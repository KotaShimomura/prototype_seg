{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "upper-quilt",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: cython in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 1)) (0.28.4)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 2)) (1.19.2)\n",
      "Requirement already satisfied: cffi in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 3)) (1.14.3)\n",
      "Requirement already satisfied: opencv-python in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 4)) (4.4.0.46)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 5)) (1.6.0)\n",
      "Requirement already satisfied: easydict in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 6)) (1.10)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 7)) (3.3.4)\n",
      "Collecting Pillow>=6.2.2\n",
      "  Using cached Pillow-9.3.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "Requirement already satisfied: torchcontrib in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 9)) (0.0.2)\n",
      "Requirement already satisfied: yacs in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 10)) (0.1.8)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 11)) (5.4.1)\n",
      "Requirement already satisfied: visdom in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 12)) (0.2.3)\n",
      "Requirement already satisfied: bs4 in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 13)) (0.0.1)\n",
      "Requirement already satisfied: html5lib in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 14)) (1.1)\n",
      "Requirement already satisfied: ninja in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 15)) (1.11.1)\n",
      "Requirement already satisfied: torch>=1.7.0 in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 16)) (1.8.0a0+52ea372)\n",
      "Requirement already satisfied: torchvision>=0.6.0 in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 17)) (0.9.0a0)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.8/site-packages (from cffi->-r requirements.txt (line 3)) (2.20)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib->-r requirements.txt (line 7)) (2.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.8/site-packages (from matplotlib->-r requirements.txt (line 7)) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib->-r requirements.txt (line 7)) (1.3.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /opt/conda/lib/python3.8/site-packages (from matplotlib->-r requirements.txt (line 7)) (2.4.7)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from visdom->-r requirements.txt (line 12)) (1.15.0)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.8/site-packages (from visdom->-r requirements.txt (line 12)) (2.8.5)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from visdom->-r requirements.txt (line 12)) (2.24.0)\n",
      "Requirement already satisfied: tornado in /opt/conda/lib/python3.8/site-packages (from visdom->-r requirements.txt (line 12)) (6.1)\n",
      "Requirement already satisfied: pillow-simd in /opt/conda/lib/python3.8/site-packages (from visdom->-r requirements.txt (line 12)) (7.0.0.post3)\n",
      "Requirement already satisfied: jsonpatch in /opt/conda/lib/python3.8/site-packages (from visdom->-r requirements.txt (line 12)) (1.32)\n",
      "Requirement already satisfied: websocket-client in /opt/conda/lib/python3.8/site-packages (from visdom->-r requirements.txt (line 12)) (1.4.2)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.8/site-packages (from bs4->-r requirements.txt (line 13)) (4.9.3)\n",
      "Requirement already satisfied: webencodings in /opt/conda/lib/python3.8/site-packages (from html5lib->-r requirements.txt (line 14)) (0.5.1)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.8/site-packages (from torch>=1.7.0->-r requirements.txt (line 16)) (3.7.4.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->visdom->-r requirements.txt (line 12)) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->visdom->-r requirements.txt (line 12)) (1.25.11)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.8/site-packages (from requests->visdom->-r requirements.txt (line 12)) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->visdom->-r requirements.txt (line 12)) (2020.12.5)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.8/site-packages (from jsonpatch->visdom->-r requirements.txt (line 12)) (2.3)\n",
      "Requirement already satisfied: soupsieve>1.2; python_version >= \"3.0\" in /opt/conda/lib/python3.8/site-packages (from beautifulsoup4->bs4->-r requirements.txt (line 13)) (2.1)\n",
      "Installing collected packages: Pillow\n",
      "  Attempting uninstall: Pillow\n",
      "    Found existing installation: Pillow 6.2.1\n",
      "    Uninstalling Pillow-6.2.1:\n",
      "      Successfully uninstalled Pillow-6.2.1\n",
      "Successfully installed Pillow-9.3.0\n",
      "Collecting pillow==6.2.1\n",
      "  Using cached Pillow-6.2.1-cp38-cp38-manylinux1_x86_64.whl (2.1 MB)\n",
      "Installing collected packages: pillow\n",
      "  Attempting uninstall: pillow\n",
      "    Found existing installation: Pillow 9.3.0\n",
      "    Uninstalling Pillow-9.3.0:\n",
      "      Successfully uninstalled Pillow-9.3.0\n",
      "Successfully installed pillow-6.2.1\n",
      "Requirement already satisfied: einops in /opt/conda/lib/python3.8/site-packages (0.5.0)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "./env.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "disturbed-modeling",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import pdb\n",
    "\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "unlike-glasgow",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pdb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.distributed as dist\n",
    "\n",
    "from lib.models.backbones.backbone_selector import BackboneSelector\n",
    "from lib.models.tools.module_helper import ModuleHelper\n",
    "from lib.models.modules.projection import ProjectionHead\n",
    "from lib.utils.tools.logger import Logger as Log\n",
    "from lib.models.modules.hanet_attention import HANet_Conv\n",
    "from lib.models.modules.contrast import momentum_update, l2_normalize, ProjectionHead\n",
    "from lib.models.modules.sinkhorn import distributed_sinkhorn\n",
    "from timm.models.layers import trunc_normal_\n",
    "from einops import rearrange, repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "billion-stranger",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    model_method = 'fcn'\n",
    "    phase = 'infer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "partial-closing",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.models.nets.hrnet import HRNet_W48_Proto\n",
    "import argparse\n",
    "\n",
    "DATA_ROOT = '/tmp/working/workspace/ProtoSeg_local/data'\n",
    "SCRATCH_ROOT = '/tmp/working/workspace/ProtoSeg_local/output'\n",
    "ASSET_ROOT = '/tmp/working/workspace/ProtoSeg_local/checkpoints/cityscapes/'\n",
    "\n",
    "BACKBONE=\"hrnet48\"\n",
    "DATA_DIR = DATA_ROOT + '/Cityscapes'\n",
    "# SAVE_DIR = SCRATCH_ROOT + '/Cityscapes/seg_results/'\n",
    "# SAVE_DIR = '/tmp/working/workspace/PP_seg/output/Cityscapes/seg_results/'\n",
    "SAVE_DIR = '/tmp/working/workspace/ProtoSeg_local/output/Cityscapes/seg_results/'\n",
    "\n",
    "CHECKPOINTS_ROOT = SCRATCH_ROOT + \"/Cityscapes\"\n",
    "\n",
    "MODEL_NAME=\"hrnet_w48_proto\"\n",
    "LOSS_TYPE=\"pixel_prototype_ce_loss\"\n",
    "CHECKPOINTS_NAME = \"hrnet_w48_proto_lr1x_hrnet_proto_80k\"\n",
    "\n",
    "def main(): \n",
    "    def str2bool(v):\n",
    "        \"\"\" Usage:\n",
    "        parser.add_argument('--pretrained', type=str2bool, nargs='?', const=True,\n",
    "                            dest='pretrained', help='Whether to use pretrained models.')\n",
    "        \"\"\"\n",
    "        if v.lower() in ('yes', 'true', 't', 'y', '1'):\n",
    "            return True\n",
    "        elif v.lower() in ('no', 'false', 'f', 'n', '0'):\n",
    "            return False\n",
    "        else:\n",
    "            raise argparse.ArgumentTypeError('Unsupported value encountered.')\n",
    "\n",
    "\n",
    "    # load model\n",
    "    parser.add_argument('--phase', default='train', type=str, dest='phase')\n",
    "    parser.add_argument('--model_method', default='fcn', type=str, dest='model_method')\n",
    "    parser.add_argument('--network', default='hrnet_w48_proto', type=str, dest='network')\n",
    "    parser.add_argument('--model_name', default=\"hrnet_w48_proto\", type=str, dest='model_name')\n",
    "    parser.add_argument('--configs', default='configs/cityscapes/H_48_D_4_proto.json', type=str,dest='configs', help='The file of the hyper parameters.')\n",
    "    parser.add_argument('REMAIN', nargs='*')\n",
    "    parser.add_argument('--gpu', default=[0, 1, 2, 3], nargs='+', type=int, dest='gpu', help='The gpu list used.')\n",
    "    parser.add_argument('--test_img', default=None, type=str, dest='test:test_img', help='The test path of image.')\n",
    "    parser.add_argument('--test_dir', default=None, type=str, dest='test:test_dir', help='The test directory of images.')\n",
    "    parser.add_argument('--out_dir', default='none', type=str, dest='test:out_dir', help='The test out directory of images.')\n",
    "    parser.add_argument('--save_prob', type=str2bool, nargs='?', default=False, dest='test:save_prob', help='Save the logits map during testing.')\n",
    "    parser.add_argument('--drop_last', type=str2bool, nargs='?', default=False, dest='data:drop_last', help='Fix bug for syncbn.')\n",
    "    parser.add_argument('--data_dir', default=None, type=str, nargs='+', dest='data:data_dir', help='The Directory of the data.')\n",
    "    parser.add_argument('--backbone', default=None, type=str, dest='network:backbone', help='The base network of model.')\n",
    "    parser.add_argument('--checkpoints_name', default='hrnet_w48_proto_lr1x_hrnet_proto_80k', type=str, dest='checkpoints:checkpoints_name', help='The name of checkpoint model.')\n",
    "    parser.add_argument('--resume', default=None, type=str, dest='network:resume', help='The path of checkpoints.')\n",
    "    parser.add_argument('--loss_type', default='pixel_prototype_ce_loss', type=str, dest='loss:loss_type', help='The loss type of the network.')\n",
    "\n",
    "    # start inference\n",
    "\n",
    "\n",
    "    # python\n",
    "    #args = parser.parse_args()\n",
    "\n",
    "    # jupyter\n",
    "    # args_parser = parser.parse_args(args=['--phase',\n",
    "    #                                       '--model_method',\n",
    "    #                                       '--network',\n",
    "    #                                       '--model_name'])\n",
    "\n",
    "    args_parser = parser.parse_args(args=['--phase', 'test',\n",
    "                                         '--test_dir', DATA_DIR + '/val/image',\n",
    "                                         '--out_dir', SAVE_DIR + CHECKPOINTS_NAME + '_val_ms',\n",
    "                                         '--drop_last','y',\n",
    "                                         '--data_dir',DATA_DIR,\n",
    "                                         '--backbone', BACKBONE,\n",
    "                                         '--model_name',MODEL_NAME,\n",
    "                                         '--resume',CHECKPOINTS_ROOT+'/checkpoints/cityscapes/'+CHECKPOINTS_NAME+'_latest.pth',\n",
    "                                         '--loss_type ',LOSS_TYPE])\n",
    "    \n",
    "    return args_parser\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "lucky-discovery",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_fn():\n",
    "    parser.add_argument('--gt_dir', default=None, type=str, dest='gt_dir', help='The directory of ground truth.')\n",
    "    parser.add_argument('--pred_dir', default=None, type=str, dest='pred_dir', help='The directory of predicted labels.')\n",
    "\n",
    "    args = parser.parse_args(args=['--pred_dir',SAVE_DIR + CHECKPOINTS_NAME + '_val_ms/label',\n",
    "                                   '--gt_dir', DATA_DIR + '/val/label'])\n",
    "    \n",
    "    return args"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "roman-beverage",
   "metadata": {},
   "source": [
    "# utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "different-sleeping",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from ast import literal_eval\n",
    "\n",
    "class Configer(object):\n",
    "\n",
    "    def __init__(self, args_parser=None, configs=None, config_dict=None):\n",
    "        if config_dict is not None:\n",
    "            self.params_root = config_dict\n",
    "\n",
    "        elif configs is not None:\n",
    "            if not os.path.exists(configs):\n",
    "                exit(0)\n",
    "\n",
    "            json_stream = open(configs, 'r')\n",
    "            self.params_root = json.load(json_stream)\n",
    "            json_stream.close()\n",
    "\n",
    "        elif args_parser is not None:\n",
    "            self.args_dict = args_parser.__dict__\n",
    "            self.params_root = None\n",
    "\n",
    "            if not os.path.exists(args_parser.configs):\n",
    "                print('Json Path:{} not exists!'.format(args_parser.configs))\n",
    "                exit(1)\n",
    "\n",
    "            json_stream = open(args_parser.configs, 'r')\n",
    "            self.params_root = json.load(json_stream)\n",
    "            json_stream.close()\n",
    "\n",
    "            for key, value in self.args_dict.items():\n",
    "                if not self.exists(*key.split(':')):\n",
    "                    self.add(key.split(':'), value)\n",
    "                elif value is not None:\n",
    "                    self.update(key.split(':'), value)\n",
    "\n",
    "            self._handle_remaining_args(args_parser.REMAIN)\n",
    "\n",
    "        self.conditions = _ConditionHelper(self)\n",
    "\n",
    "\n",
    "    def _handle_remaining_args(self, remain):\n",
    "\n",
    "        def _parse_value(x: str):\n",
    "            \"\"\"\n",
    "            We first try to parse `x` as python literal object.\n",
    "            If failed, we regard x as string.\n",
    "            \"\"\"\n",
    "            try:\n",
    "                return literal_eval(x)\n",
    "            except ValueError:\n",
    "                return x\n",
    "\n",
    "        def _set_value(key, value):\n",
    "            \"\"\"\n",
    "            We directly operate on `params_root`.\n",
    "            \"\"\"\n",
    "            remained_parts = key.split('.')\n",
    "            consumed_parts = []\n",
    "\n",
    "            parent_dict = self.params_root\n",
    "            while len(remained_parts) > 1:\n",
    "                cur_key = remained_parts.pop(0)\n",
    "                consumed_parts.append(cur_key)\n",
    "\n",
    "                if cur_key not in parent_dict:\n",
    "                    parent_dict[cur_key] = dict()\n",
    "                elif not isinstance(parent_dict[cur_key], dict):\n",
    "                    sys.exit(1)\n",
    "                \n",
    "                parent_dict = parent_dict[cur_key]\n",
    "\n",
    "            cur_key = remained_parts.pop(0)\n",
    "            consumed_parts.append(cur_key)\n",
    "\n",
    "            if cur_key.endswith('+'):\n",
    "                cur_key = cur_key[:-1]\n",
    "                target = parent_dict.get(cur_key)\n",
    "\n",
    "                if not isinstance(target, list):\n",
    "                    sys.exit(1)\n",
    "\n",
    "                target.append(value)\n",
    "                return\n",
    "\n",
    "            existing_value = parent_dict.get(cur_key)\n",
    "#             if existing_value is not None:\n",
    "#             else:\n",
    "            parent_dict[cur_key] = value\n",
    "\n",
    "        assert len(remain) % 2 == 0, remain\n",
    "        args = {}\n",
    "        for i in range(len(remain) // 2):\n",
    "            key, value = remain[2 * i: 2 * i + 2]\n",
    "            _set_value(key, _parse_value(value))\n",
    "\n",
    "    def clone(self):\n",
    "        from copy import deepcopy\n",
    "        return Configer(config_dict=deepcopy(self.params_root))\n",
    "\n",
    "    def _get_caller(self):\n",
    "        filename = os.path.basename(sys._getframe().f_back.f_back.f_code.co_filename)\n",
    "        lineno = sys._getframe().f_back.f_back.f_lineno\n",
    "        prefix = '{}, {}'.format(filename, lineno)\n",
    "        return prefix\n",
    "\n",
    "    def get(self, *key):\n",
    "        if len(key) == 0:\n",
    "            return self.params_root\n",
    "\n",
    "        elif len(key) == 1:\n",
    "            if key[0] in self.params_root:\n",
    "                return self.params_root[key[0]]\n",
    "            else:\n",
    "                exit(1)\n",
    "\n",
    "        elif len(key) == 2:\n",
    "            if key[0] in self.params_root and key[1] in self.params_root[key[0]]:\n",
    "                return self.params_root[key[0]][key[1]]\n",
    "            else:\n",
    "                exit(1)\n",
    "\n",
    "        else:\n",
    "            exit(1)\n",
    "\n",
    "    def exists(self, *key):\n",
    "        if len(key) == 1 and key[0] in self.params_root:\n",
    "            return True\n",
    "\n",
    "        if len(key) == 2 and (key[0] in self.params_root and key[1] in self.params_root[key[0]]):\n",
    "            return True\n",
    "\n",
    "        return False\n",
    "\n",
    "    def add(self, key_tuple, value):\n",
    "        if self.exists(*key_tuple):\n",
    "            exit(1)\n",
    "\n",
    "        if len(key_tuple) == 1:\n",
    "            self.params_root[key_tuple[0]] = value\n",
    "\n",
    "        elif len(key_tuple) == 2:\n",
    "            if key_tuple[0] not in self.params_root:\n",
    "                self.params_root[key_tuple[0]] = dict()\n",
    "\n",
    "            self.params_root[key_tuple[0]][key_tuple[1]] = value\n",
    "\n",
    "        else:\n",
    "            exit(1)\n",
    "\n",
    "    def update(self, key_tuple, value):\n",
    "        if not self.exists(*key_tuple):\n",
    "            exit(1)\n",
    "\n",
    "        if len(key_tuple) == 1 and not isinstance(self.params_root[key_tuple[0]], dict):\n",
    "            self.params_root[key_tuple[0]] = value\n",
    "\n",
    "        elif len(key_tuple) == 2:\n",
    "            self.params_root[key_tuple[0]][key_tuple[1]] = value\n",
    "\n",
    "        else:\n",
    "            exit(1)\n",
    "\n",
    "    def resume(self, config_dict):\n",
    "        self.params_root = config_dict\n",
    "\n",
    "    def plus_one(self, *key):\n",
    "        if not self.exists(*key):\n",
    "            exit(1)\n",
    "\n",
    "        if len(key) == 1 and not isinstance(self.params_root[key[0]], dict):\n",
    "            self.params_root[key[0]] += 1\n",
    "\n",
    "        elif len(key) == 2:\n",
    "            self.params_root[key[0]][key[1]] += 1\n",
    "\n",
    "        else:\n",
    "            exit(1)\n",
    "\n",
    "    def to_dict(self):\n",
    "        return self.params_root\n",
    "\n",
    "\n",
    "class _ConditionHelper:\n",
    "    \"\"\"Handy helper\"\"\"\n",
    "\n",
    "    def __init__(self, configer):\n",
    "        self.configer = configer\n",
    "\n",
    "    @property\n",
    "    def use_multi_dataset(self):\n",
    "        root_dirs = self.configer.get('data', 'data_dir')\n",
    "        return isinstance(root_dirs, (tuple, list)) and len(root_dirs) > 1\n",
    "\n",
    "    @property\n",
    "    def pred_sw_offset(self):\n",
    "        return self.configer.exists('data', 'pred_sw_offset')\n",
    "\n",
    "    @property\n",
    "    def pred_dt_offset(self):\n",
    "        return self.configer.exists('data', 'pred_dt_offset')\n",
    "\n",
    "    @property\n",
    "    def use_sw_offset(self):\n",
    "        return self.configer.exists('data', 'use_sw_offset')\n",
    "\n",
    "    @property\n",
    "    def use_dt_offset(self):\n",
    "        return self.configer.exists('data', 'use_dt_offset')\n",
    "\n",
    "    @property\n",
    "    def use_ground_truth(self):\n",
    "        return self.config_equals(('use_ground_truth',), True)\n",
    "\n",
    "    @property\n",
    "    def pred_ml_dt_offset(self):\n",
    "        return self.configer.exists('data', 'pred_ml_dt_offset')\n",
    "\n",
    "    def loss_contains(self, name):\n",
    "        return name in self.configer.get('loss', 'loss_type')\n",
    "\n",
    "    def model_contains(self, name):\n",
    "        return name in self.configer.get('network', 'model_name')\n",
    "\n",
    "    def config_equals(self, key, value):\n",
    "        if not self.configer.exists(*key):\n",
    "            return False\n",
    "\n",
    "        return self.configer.get(*key) == value\n",
    "\n",
    "    def config_exists(self, key):\n",
    "        return self.configer.exists(*key)\n",
    "\n",
    "    def environ_exists(self, key):\n",
    "        return os.environ.get(key) is not None\n",
    "\n",
    "    @property\n",
    "    def diverse_size(self):\n",
    "        return self.configer.get('val', 'data_transformer')['size_mode'] == 'diverse_size'\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\" Computes ans stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0.\n",
    "        self.avg = 0.\n",
    "        self.sum = 0.\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "chicken-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb\n",
    "import torch\n",
    "from torch.utils import data\n",
    "\n",
    "import lib.datasets.tools.transforms as trans\n",
    "import lib.datasets.tools.cv2_aug_transforms as cv2_aug_trans\n",
    "import lib.datasets.tools.pil_aug_transforms as pil_aug_trans\n",
    "from lib.datasets.loader.default_loader import DefaultLoader, CSDataTestLoader\n",
    "from lib.datasets.tools.collate import collate\n",
    "from lib.utils.tools.logger import Logger as Log\n",
    "\n",
    "from lib.utils.distributed import get_world_size, get_rank, is_distributed\n",
    "\n",
    "class DataLoader(object):\n",
    "\n",
    "    def __init__(self, configer):\n",
    "        self.configer = configer\n",
    "\n",
    "        from lib.datasets.tools import cv2_aug_transforms\n",
    "        self.aug_train_transform = cv2_aug_transforms.CV2AugCompose(self.configer, split='train')\n",
    "        self.aug_val_transform = cv2_aug_transforms.CV2AugCompose(self.configer, split='val')\n",
    "\n",
    "        self.img_transform = trans.Compose([\n",
    "            trans.ToTensor(),\n",
    "            trans.Normalize(div_value=self.configer.get('normalize', 'div_value'),\n",
    "                            mean=self.configer.get('normalize', 'mean'),\n",
    "                            std=self.configer.get('normalize', 'std')), ])\n",
    "\n",
    "        self.label_transform = trans.Compose([\n",
    "            trans.ToLabel(),\n",
    "            trans.ReLabel(255, -1), ])\n",
    " \n",
    "    def get_dataloader_sampler(self, klass, split, dataset):\n",
    "\n",
    "        from lib.datasets.loader.multi_dataset_loader import MultiDatasetLoader, MultiDatasetTrainingSampler\n",
    "\n",
    "        root_dir = self.configer.get('data', 'data_dir')\n",
    "        if isinstance(root_dir, list) and len(root_dir) == 1:\n",
    "            root_dir = root_dir[0]\n",
    "\n",
    "        kwargs = dict(\n",
    "            dataset=dataset,\n",
    "            aug_transform=(self.aug_train_transform if split == 'train' else self.aug_val_transform),\n",
    "            img_transform=self.img_transform,\n",
    "            label_transform=self.label_transform,\n",
    "            configer=self.configer\n",
    "        )\n",
    "\n",
    "        if isinstance(root_dir, str):\n",
    "            loader = klass(root_dir, **kwargs)\n",
    "            multi_dataset = False\n",
    "        elif isinstance(root_dir, list):\n",
    "            loader = MultiDatasetLoader(root_dir, klass, **kwargs)\n",
    "            multi_dataset = True\n",
    "            Log.info('use multi-dataset for {}...'.format(dataset))\n",
    "        else:\n",
    "            raise RuntimeError('Unknown root dir {}'.format(root_dir))\n",
    "\n",
    "        if split == 'train':\n",
    "            if is_distributed() and multi_dataset:\n",
    "                raise RuntimeError('Currently multi dataset doesn\\'t support distributed.')\n",
    "\n",
    "            if is_distributed():\n",
    "                sampler = torch.utils.data.distributed.DistributedSampler(loader)\n",
    "            elif multi_dataset:\n",
    "                sampler = MultiDatasetTrainingSampler(loader)\n",
    "            else:\n",
    "                sampler = None\n",
    "\n",
    "        elif split == 'val':\n",
    "\n",
    "            if is_distributed():\n",
    "                sampler = torch.utils.data.distributed.DistributedSampler(loader)\n",
    "            else:\n",
    "                sampler = None\n",
    "\n",
    "        return loader, sampler\n",
    "\n",
    "    def get_valloader(self, dataset=None):\n",
    "        dataset = 'val' if dataset is None else dataset\n",
    "\n",
    "        if self.configer.exists('data', 'use_dt_offset') or self.configer.exists('data', 'pred_dt_offset'):\n",
    "            \"\"\"\n",
    "            dt-offset manner:\n",
    "            load both the ground-truth label and offset (based on distance transform).\n",
    "            \"\"\"\n",
    "            Log.info('use distance transform based offset loader for val ...')\n",
    "            klass = DTOffsetLoader\n",
    "\n",
    "        elif self.configer.get('method') == 'fcn_segmentor':\n",
    "            \"\"\"\n",
    "            default manner:\n",
    "            load the ground-truth label.\n",
    "            \"\"\"\n",
    "            Log.info('use DefaultLoader for val ...')\n",
    "            klass = DefaultLoader\n",
    "        else:\n",
    "            Log.error('Method: {} loader is invalid.'.format(self.configer.get('method')))\n",
    "            return None\n",
    "\n",
    "        loader, sampler = self.get_dataloader_sampler(klass, 'val', dataset)\n",
    "        valloader = data.DataLoader(\n",
    "            loader,\n",
    "            sampler=sampler,\n",
    "            batch_size=self.configer.get('val', 'batch_size') // get_world_size(), pin_memory=False,\n",
    "            num_workers=self.configer.get('data', 'workers'), shuffle=False,\n",
    "            collate_fn=lambda *args: collate(\n",
    "                *args, trans_dict=self.configer.get('val', 'data_transformer')\n",
    "            )\n",
    "        )\n",
    "        return valloader\n",
    "\n",
    "    def get_testloader(self, dataset=None):\n",
    "        dataset = 'test' if dataset is None else dataset\n",
    "        if self.configer.exists('data', 'use_sw_offset') or self.configer.exists('data', 'pred_sw_offset'):\n",
    "            Log.info('use sliding window based offset loader for test ...')\n",
    "            test_loader = data.DataLoader(\n",
    "                SWOffsetTestLoader(root_dir=self.configer.get('data', 'data_dir'), dataset=dataset,\n",
    "                                   img_transform=self.img_transform,\n",
    "                                   configer=self.configer),\n",
    "                batch_size=self.configer.get('test', 'batch_size'), pin_memory=False,\n",
    "                num_workers=self.configer.get('data', 'workers'), shuffle=False,\n",
    "                collate_fn=lambda *args: collate(\n",
    "                    *args, trans_dict=self.configer.get('test', 'data_transformer')\n",
    "                )\n",
    "            )\n",
    "            return test_loader\n",
    "\n",
    "        elif self.configer.get('method') == 'fcn_segmentor':\n",
    "            Log.info('use CSDataTestLoader for test ...')\n",
    "\n",
    "            root_dir = self.configer.get('data', 'data_dir')\n",
    "            if isinstance(root_dir, list) and len(root_dir) == 1:\n",
    "                root_dir = root_dir[0]\n",
    "            test_loader = data.DataLoader(\n",
    "                CSDataTestLoader(root_dir=root_dir, dataset=dataset,\n",
    "                                 img_transform=self.img_transform,\n",
    "                                 configer=self.configer),\n",
    "                batch_size=self.configer.get('test', 'batch_size'), pin_memory=True,\n",
    "                num_workers=self.configer.get('data', 'workers'), shuffle=False,\n",
    "                collate_fn=lambda *args: collate(\n",
    "                    *args, trans_dict=self.configer.get('test', 'data_transformer')\n",
    "                )\n",
    "            )\n",
    "            return test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rising-windows",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "functioning-tyler",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HRNet_W48_Proto(nn.Module):\n",
    "    \"\"\"\n",
    "    deep high-resolution representation learning for human pose estimation, CVPR2019\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, configer):\n",
    "        super(HRNet_W48_Proto, self).__init__()\n",
    "        self.configer = configer\n",
    "        self.gamma = self.configer.get('protoseg', 'gamma')\n",
    "        self.num_prototype = self.configer.get('protoseg', 'num_prototype')\n",
    "        self.use_prototype = self.configer.get('protoseg', 'use_prototype')\n",
    "        self.update_prototype = self.configer.get('protoseg', 'update_prototype')\n",
    "        self.pretrain_prototype = self.configer.get('protoseg', 'pretrain_prototype')\n",
    "        self.num_classes = self.configer.get('data', 'num_classes')\n",
    "        self.backbone = BackboneSelector(configer).get_backbone()\n",
    "\n",
    "        in_channels = 720\n",
    "        self.cls_head = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, in_channels, kernel_size=3, stride=1, padding=1),\n",
    "            ModuleHelper.BNReLU(in_channels, bn_type=self.configer.get('network', 'bn_type')),\n",
    "            nn.Dropout2d(0.10)\n",
    "        )\n",
    "\n",
    "        self.prototypes = nn.Parameter(torch.zeros(self.num_classes, self.num_prototype, in_channels),\n",
    "                                       requires_grad=True)\n",
    "\n",
    "        self.proj_head = ProjectionHead(in_channels, in_channels)\n",
    "        self.feat_norm = nn.LayerNorm(in_channels)\n",
    "        self.mask_norm = nn.LayerNorm(self.num_classes)\n",
    "\n",
    "        trunc_normal_(self.prototypes, std=0.02)\n",
    "\n",
    "    def prototype_learning(self, _c, out_seg, gt_seg, masks):\n",
    "        pred_seg = torch.max(out_seg, 1)[1]\n",
    "        mask = (gt_seg == pred_seg.view(-1))\n",
    "\n",
    "        cosine_similarity = torch.mm(_c, self.prototypes.view(-1, self.prototypes.shape[-1]).t())\n",
    "\n",
    "        proto_logits = cosine_similarity\n",
    "        proto_target = gt_seg.clone().float()\n",
    "\n",
    "        # clustering for each class\n",
    "        protos = self.prototypes.data.clone()\n",
    "        for k in range(self.num_classes):\n",
    "            init_q = masks[..., k]\n",
    "            init_q = init_q[gt_seg == k, ...]\n",
    "            if init_q.shape[0] == 0:\n",
    "                continue\n",
    "\n",
    "            q, indexs = distributed_sinkhorn(init_q)\n",
    "\n",
    "            m_k = mask[gt_seg == k]\n",
    "\n",
    "            c_k = _c[gt_seg == k, ...]\n",
    "\n",
    "            m_k_tile = repeat(m_k, 'n -> n tile', tile=self.num_prototype)\n",
    "\n",
    "            m_q = q * m_k_tile  # n x self.num_prototype\n",
    "\n",
    "            c_k_tile = repeat(m_k, 'n -> n tile', tile=c_k.shape[-1])\n",
    "\n",
    "            c_q = c_k * c_k_tile  # n x embedding_dim\n",
    "\n",
    "            f = m_q.transpose(0, 1) @ c_q  # self.num_prototype x embedding_dim\n",
    "\n",
    "            n = torch.sum(m_q, dim=0)\n",
    "\n",
    "            if torch.sum(n) > 0 and self.update_prototype is True:\n",
    "                f = F.normalize(f, p=2, dim=-1)\n",
    "\n",
    "                new_value = momentum_update(old_value=protos[k, n != 0, :], new_value=f[n != 0, :],\n",
    "                                            momentum=self.gamma, debug=False)\n",
    "                protos[k, n != 0, :] = new_value\n",
    "\n",
    "            proto_target[gt_seg == k] = indexs.float() + (self.num_prototype * k)\n",
    "\n",
    "        self.prototypes = nn.Parameter(l2_normalize(protos),\n",
    "                                       requires_grad=False)\n",
    "\n",
    "        if dist.is_available() and dist.is_initialized():\n",
    "            protos = self.prototypes.data.clone()\n",
    "            dist.all_reduce(protos.div_(dist.get_world_size()))\n",
    "            self.prototypes = nn.Parameter(protos, requires_grad=False)\n",
    "\n",
    "        return proto_logits, proto_target\n",
    "\n",
    "    def forward(self, x_, gt_semantic_seg=None, pretrain_prototype=False):\n",
    "        x = self.backbone(x_)\n",
    "        _, _, h, w = x[0].size()\n",
    "\n",
    "        feat1 = x[0]\n",
    "        feat2 = F.interpolate(x[1], size=(h, w), mode=\"bilinear\", align_corners=True)\n",
    "        feat3 = F.interpolate(x[2], size=(h, w), mode=\"bilinear\", align_corners=True)\n",
    "        feat4 = F.interpolate(x[3], size=(h, w), mode=\"bilinear\", align_corners=True)\n",
    "\n",
    "        feats = torch.cat([feat1, feat2, feat3, feat4], 1)\n",
    "        c = self.cls_head(feats)\n",
    "\n",
    "        c = self.proj_head(c)\n",
    "        _c = rearrange(c, 'b c h w -> (b h w) c')\n",
    "        _c = self.feat_norm(_c)\n",
    "        _c = l2_normalize(_c)\n",
    "\n",
    "        self.prototypes.data.copy_(l2_normalize(self.prototypes))\n",
    "\n",
    "        # n: h*w, k: num_class, m: num_prototype\n",
    "        masks = torch.einsum('nd,kmd->nmk', _c, self.prototypes)\n",
    "        prototype = self.prototypes\n",
    "\n",
    "        out_seg = torch.amax(masks, dim=1)\n",
    "        out_seg = self.mask_norm(out_seg)\n",
    "        out_seg = rearrange(out_seg, \"(b h w) k -> b k h w\", b=feats.shape[0], h=feats.shape[2])\n",
    "\n",
    "        if pretrain_prototype is False and self.use_prototype is True and gt_semantic_seg is not None:\n",
    "            print('pretrain_prototype & if in')\n",
    "            gt_seg = F.interpolate(gt_semantic_seg.float(), size=feats.size()[2:], mode='nearest').view(-1)\n",
    "            contrast_logits, contrast_target = self.prototype_learning(_c, out_seg, gt_seg, masks)\n",
    "            return {'seg': out_seg, 'logits': contrast_logits, 'target': contrast_target}\n",
    "\n",
    "        return out_seg, prototype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "varied-wildlife",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from lib.models.nets.hrnet import HRNet_W48_Proto\n",
    "\n",
    "SEG_MODEL_DICT = {\n",
    "    'hrnet_w48_proto': HRNet_W48_Proto\n",
    "}\n",
    "\n",
    "class Segmentation_Model(object):\n",
    "    def __init__(self, configer):\n",
    "        self.configer = configer\n",
    "\n",
    "    def semantic_segmentor(self):\n",
    "        # ここよくわからん\n",
    "        #model_name = self.configer.get('network', 'model_name')\n",
    "        model_name = 'hrnet_w48_proto'\n",
    "\n",
    "        if model_name not in SEG_MODEL_DICT:\n",
    "            print(\"your select model not found\")\n",
    "        print(model_name)\n",
    "#         model= SEG_MODEL_DICT[model_name](self.configer)\n",
    "        model= HRNet_W48_Proto(self.configer)\n",
    "        print('ok')\n",
    "\n",
    "        return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "freelance-pavilion",
   "metadata": {},
   "source": [
    "# Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fresh-airfare",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.loss.loss_helper import FSAuxOhemCELoss, FSOhemCELoss, FSRMILoss\n",
    "from lib.loss.loss_helper import FSCELoss, FSAuxCELoss, FSAuxRMILoss, FSCELOVASZLoss, MSFSAuxRMILoss, FSAuxCELossDSN\n",
    "from lib.loss.loss_helper import SegFixLoss\n",
    "from lib.loss.rmi_loss import RMILoss\n",
    "from lib.loss.loss_contrast import ContrastAuxCELoss, ContrastCELoss\n",
    "from lib.loss.loss_contrast_mem import ContrastCELoss as MemContrastCELoss\n",
    "from lib.loss.loss_proto import PixelPrototypeCELoss\n",
    "\n",
    "SEG_LOSS_DICT = {\n",
    "    'fs_ce_loss': FSCELoss,\n",
    "    'fs_ohemce_loss': FSOhemCELoss,\n",
    "    'fs_auxce_loss': FSAuxCELoss,\n",
    "    'fs_aux_rmi_loss': FSAuxRMILoss,\n",
    "    'fs_auxohemce_loss': FSAuxOhemCELoss,\n",
    "    'segfix_loss': SegFixLoss,\n",
    "    'rmi_loss': RMILoss,\n",
    "    'fs_rmi_loss': FSRMILoss,\n",
    "    'contrast_auxce_loss': ContrastAuxCELoss,\n",
    "    'contrast_ce_loss': ContrastCELoss,\n",
    "    'fs_ce_lovasz_loss': FSCELOVASZLoss,\n",
    "    'ms_fs_aux_rmi_loss': MSFSAuxRMILoss,\n",
    "    'fs_auxce_dsn_loss': FSAuxCELossDSN,\n",
    "    'mem_contrast_ce_loss': MemContrastCELoss,\n",
    "    'pixel_prototype_ce_loss': PixelPrototypeCELoss\n",
    "}\n",
    "\n",
    "class LossManager(object):\n",
    "    def __init__(self, configer):\n",
    "        self.configer = configer\n",
    "\n",
    "    def _parallel(self, loss):\n",
    "        if is_distributed():\n",
    "            Log.info('use distributed loss')\n",
    "            return loss\n",
    "            \n",
    "        if self.configer.get('network', 'loss_balance') and len(self.configer.get('gpu')) > 1:\n",
    "            Log.info('use DataParallelCriterion loss')\n",
    "            from lib.extensions.parallel.data_parallel import DataParallelCriterion\n",
    "            loss = DataParallelCriterion(loss)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def get_seg_loss(self, loss_type=None):\n",
    "        key = self.configer.get('loss', 'loss_type') if loss_type is None else loss_type\n",
    "        if key not in SEG_LOSS_DICT:\n",
    "            Log.error('Loss: {} not valid!'.format(key))\n",
    "            exit(1)\n",
    "        Log.info('use loss: {}.'.format(key))\n",
    "        loss = SEG_LOSS_DICT[key](self.configer)\n",
    "        return self._parallel(loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "still-vegetarian",
   "metadata": {},
   "source": [
    "# optim & scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "nearby-deployment",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import torchcontrib\n",
    "from torch.optim import SGD, Adam, AdamW, lr_scheduler\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "\n",
    "from lib.utils.tools.logger import Logger as Log\n",
    "\n",
    "\n",
    "class WarmupCosineSchedule(LambdaLR):\n",
    "    \"\"\" Linear warmup and then cosine decay.\n",
    "        Linearly increases learning rate from 0 to 1 over `warmup_steps` training steps.\n",
    "        Decreases learning rate from 1. to 0. over remaining `t_total - warmup_steps` steps following a cosine curve.\n",
    "        If `cycles` (default=0.5) is different from default, learning rate follows cosine function after warmup.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, optimizer, warmup_steps, t_total, cycles=.5, last_epoch=-1):\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.t_total = t_total\n",
    "        self.cycles = cycles\n",
    "        super(WarmupCosineSchedule, self).__init__(optimizer, self.lr_lambda, last_epoch=last_epoch)\n",
    "\n",
    "    def lr_lambda(self, step):\n",
    "        if step < self.warmup_steps:\n",
    "            return float(step) / float(max(1.0, self.warmup_steps))\n",
    "        # progress after warmup\n",
    "        progress = float(step - self.warmup_steps) / float(max(1, self.t_total - self.warmup_steps))\n",
    "        return max(0.0, 0.5 * (1. + math.cos(math.pi * float(self.cycles) * 2.0 * progress)))\n",
    "\n",
    "\n",
    "class OptimScheduler(object):\n",
    "    def __init__(self, configer):\n",
    "        self.configer = configer\n",
    "\n",
    "    def init_optimizer(self, net_params):\n",
    "        optimizer = None\n",
    "        if self.configer.get('optim', 'optim_method') == 'sgd':\n",
    "            optimizer = SGD(net_params,\n",
    "                            lr=self.configer.get('lr', 'base_lr'),\n",
    "                            momentum=self.configer.get('optim', 'sgd')['momentum'],\n",
    "                            weight_decay=self.configer.get('optim', 'sgd')['weight_decay'],\n",
    "                            nesterov=self.configer.get('optim', 'sgd')['nesterov'])\n",
    "\n",
    "        elif self.configer.get('optim', 'optim_method') == 'adam':\n",
    "            optimizer = Adam(net_params,\n",
    "                             lr=self.configer.get('lr', 'base_lr'),\n",
    "                             betas=self.configer.get('optim', 'adam')['betas'],\n",
    "                             eps=self.configer.get('optim', 'adam')['eps'],\n",
    "                             weight_decay=self.configer.get('optim', 'adam')['weight_decay'])\n",
    "        elif self.configer.get('optim', 'optim_method') == 'adamw':\n",
    "            optimizer = AdamW(net_params,\n",
    "                              lr=self.configer.get('lr', 'base_lr'),\n",
    "                              betas=self.configer.get('optim', 'adamw')['betas'],\n",
    "                              eps=self.configer.get('optim', 'adamw')['eps'],\n",
    "                              weight_decay=self.configer.get('optim', 'adamw')['weight_decay'])\n",
    "\n",
    "        else:\n",
    "            Log.error('Optimizer {} is not valid.'.format(self.configer.get('optim', 'optim_method')))\n",
    "            exit(1)\n",
    "\n",
    "        policy = self.configer.get('lr', 'lr_policy')\n",
    "\n",
    "        scheduler = None\n",
    "        if policy == 'step':\n",
    "            scheduler = lr_scheduler.StepLR(optimizer,\n",
    "                                            self.configer.get('lr', 'step')['step_size'],\n",
    "                                            gamma=self.configer.get('lr', 'step')['gamma'])\n",
    "\n",
    "        elif policy == 'multistep':\n",
    "            scheduler = lr_scheduler.MultiStepLR(optimizer,\n",
    "                                                 self.configer.get('lr', 'multistep')['stepvalue'],\n",
    "                                                 gamma=self.configer.get('lr', 'multistep')['gamma'])\n",
    "\n",
    "        elif policy == 'lambda_poly':\n",
    "            if os.environ.get('lambda_poly_power'):\n",
    "                _lambda_poly_power = float(os.environ.get('lambda_poly_power'))\n",
    "                Log.info('Use lambda_poly policy with power {}'.format(_lambda_poly_power))\n",
    "                lambda_poly = lambda iters: pow((1.0 - iters / self.configer.get('solver', 'max_iters')),\n",
    "                                                _lambda_poly_power)\n",
    "            elif self.configer.exists('lr', 'lambda_poly'):\n",
    "                Log.info('Use lambda_poly policy with power {}'.format(self.configer.get('lr', 'lambda_poly')['power']))\n",
    "                lambda_poly = lambda iters: pow((1.0 - iters / self.configer.get('solver', 'max_iters')),\n",
    "                                                self.configer.get('lr', 'lambda_poly')['power'])\n",
    "            else:\n",
    "                Log.info('Use lambda_poly policy with default power 0.9')\n",
    "                lambda_poly = lambda iters: pow((1.0 - iters / self.configer.get('solver', 'max_iters')), 0.9)\n",
    "            scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda_poly)\n",
    "\n",
    "        elif policy == 'lambda_cosine':\n",
    "            lambda_cosine = lambda iters: (math.cos(math.pi * iters / self.configer.get('solver', 'max_iters'))\n",
    "                                           + 1.0) / 2\n",
    "            scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda_cosine)\n",
    "\n",
    "        elif policy == 'plateau':\n",
    "            scheduler = lr_scheduler.ReduceLROnPlateau(optimizer,\n",
    "                                                       mode=self.configer.get('lr', 'plateau')['mode'],\n",
    "                                                       factor=self.configer.get('lr', 'plateau')['factor'],\n",
    "                                                       patience=self.configer.get('lr', 'plateau')['patience'],\n",
    "                                                       threshold=self.configer.get('lr', 'plateau')['threshold'],\n",
    "                                                       threshold_mode=self.configer.get('lr', 'plateau')['thre_mode'],\n",
    "                                                       cooldown=self.configer.get('lr', 'plateau')['cooldown'],\n",
    "                                                       min_lr=self.configer.get('lr', 'plateau')['min_lr'],\n",
    "                                                       eps=self.configer.get('lr', 'plateau')['eps'])\n",
    "\n",
    "        elif policy == 'swa_lambda_poly':\n",
    "            optimizer = torchcontrib.optim.SWA(optimizer)\n",
    "            normal_max_iters = int(self.configer.get('solver', 'max_iters') * 0.75)\n",
    "            swa_step_max_iters = (self.configer.get('solver',\n",
    "                                                    'max_iters') - normal_max_iters) // 5 + 1  # we use 5 ensembles here\n",
    "\n",
    "            def swa_lambda_poly(iters):\n",
    "                if iters < normal_max_iters:\n",
    "                    return pow(1.0 - iters / normal_max_iters, 0.9)\n",
    "                else:  # set lr to half of initial lr and start swa\n",
    "                    return 0.5 * pow(1.0 - ((iters - normal_max_iters) % swa_step_max_iters) / swa_step_max_iters, 0.9)\n",
    "\n",
    "            scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda=swa_lambda_poly)\n",
    "\n",
    "        elif policy == 'swa_lambda_cosine':\n",
    "            optimizer = torchcontrib.optim.SWA(optimizer)\n",
    "            normal_max_iters = int(self.configer.get('solver', 'max_iters') * 0.75)\n",
    "            swa_step_max_iters = (self.configer.get('solver',\n",
    "                                                    'max_iters') - normal_max_iters) // 5 + 1  # we use 5 ensembles here\n",
    "\n",
    "            def swa_lambda_cosine(iters):\n",
    "                if iters < normal_max_iters:\n",
    "                    return (math.cos(math.pi * iters / normal_max_iters) + 1.0) / 2\n",
    "                else:  # set lr to half of initial lr and start swa\n",
    "                    return 0.5 * (math.cos(\n",
    "                        math.pi * ((iters - normal_max_iters) % swa_step_max_iters) / swa_step_max_iters) + 1.0) / 2\n",
    "\n",
    "            scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda=swa_lambda_cosine)\n",
    "\n",
    "        elif policy == 'warmup_cosine':\n",
    "            scheduler = WarmupCosineSchedule(optimizer, warmup_steps=1000,\n",
    "                                             t_total=self.configer.get('solver', 'max_iters'))\n",
    "\n",
    "        else:\n",
    "            Log.error('Policy:{} is not valid.'.format(policy))\n",
    "            exit(1)\n",
    "\n",
    "        return optimizer, scheduler\n",
    "\n",
    "    def update_optimizer(self, net, optim_method, lr_policy):\n",
    "        self.configer.update(('optim', 'optim_method'), optim_method)\n",
    "        self.configer.update(('lr', 'lr_policy'), lr_policy)\n",
    "        optimizer, scheduler = self.init_optimizer(net)\n",
    "        return optimizer, scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "limiting-wilson",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "given-savage",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tester(object):\n",
    "    \"\"\"\n",
    "      The class for Pose Estimation. Include train, val, val & predict.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, configer):\n",
    "        self.configer = configer\n",
    "        self.batch_time = AverageMeter()\n",
    "        self.data_time = AverageMeter()\n",
    "        self.seg_visualizer = SegVisualizer(configer)\n",
    "        self.loss_manager = LossManager(configer)\n",
    "        self.module_runner = ModuleRunner(configer)\n",
    "        self.model_manager = Segmentation_Model(configer)\n",
    "        self.optim_scheduler = OptimScheduler(configer)\n",
    "        self.seg_data_loader = DataLoader(configer)\n",
    "        self.save_dir = self.configer.get('test', 'out_dir')\n",
    "        self.seg_net = None\n",
    "        self.test_loader = None\n",
    "        self.test_size = None\n",
    "        self.infer_time = 0\n",
    "        self.infer_cnt = 0\n",
    "        self._init_model()\n",
    "\n",
    "    def _init_model(self):\n",
    "        self.seg_net = self.model_manager.semantic_segmentor()\n",
    "        self.seg_net = self.module_runner.load_net(self.seg_net)\n",
    "        \n",
    "\n",
    "        if 'test' in self.save_dir:\n",
    "            self.test_loader = self.seg_data_loader.get_testloader()\n",
    "            self.test_size = len(self.test_loader) * self.configer.get('test', 'batch_size')\n",
    "        else:\n",
    "            self.test_loader = self.seg_data_loader.get_valloader()\n",
    "            self.test_size = len(self.test_loader) * self.configer.get('val', 'batch_size')\n",
    "\n",
    "        self.seg_net.eval()\n",
    "\n",
    "    def __relabel(self, label_map):\n",
    "        height, width = label_map.shape\n",
    "        label_dst = np.zeros((height, width), dtype=np.uint8)\n",
    "        for i in range(self.configer.get('data', 'num_classes')):\n",
    "            label_dst[label_map == i] = self.configer.get('data', 'label_list')[i]\n",
    "\n",
    "        label_dst = np.array(label_dst, dtype=np.uint8)\n",
    "\n",
    "        return label_dst\n",
    "\n",
    "    def test(self, data_loader=None):\n",
    "        \"\"\"\n",
    "          Validation function during the train phase.\n",
    "        \"\"\"\n",
    "        self.seg_net.eval()\n",
    "        start_time = time.time()\n",
    "        image_id = 0\n",
    "\n",
    "\n",
    "        FileHelper.make_dirs(self.save_dir, is_file=False)\n",
    "\n",
    "        if self.configer.get('dataset') in ['cityscapes', 'gta5', 'woodscape']:\n",
    "            colors = get_cityscapes_colors()\n",
    "        else:\n",
    "            raise RuntimeError(\"Unsupport colors\")\n",
    "\n",
    "        save_prob = False\n",
    "        if self.configer.get('test', 'save_prob'):\n",
    "            save_prob = self.configer.get('test', 'save_prob')\n",
    "\n",
    "            def softmax(X, axis=0):\n",
    "                max_prob = np.max(X, axis=axis, keepdims=True)\n",
    "                X -= max_prob\n",
    "                X = np.exp(X)\n",
    "                sum_prob = np.sum(X, axis=axis, keepdims=True)\n",
    "                X /= sum_prob\n",
    "                return X\n",
    "\n",
    "        for j, data_dict in enumerate(self.test_loader):\n",
    "            inputs = data_dict['img']\n",
    "            names = data_dict['name']\n",
    "            metas = data_dict['meta']\n",
    "            if 'subfolder' in data_dict:\n",
    "                subfolder = data_dict['subfolder']\n",
    "\n",
    "            if '/val/' in self.save_dir: #and os.environ.get('save_gt_label'):\n",
    "                labels = data_dict['labelmap']\n",
    "\n",
    "            with torch.no_grad():\n",
    "                # Forward pass.\n",
    "                print('Forward pass')\n",
    "                if self.configer.exists('data', 'use_offset') and self.configer.get('data', 'use_offset') == 'offline':\n",
    "                    offset_h_maps = data_dict['offsetmap_h']\n",
    "                    offset_w_maps = data_dict['offsetmap_w']\n",
    "                    outputs = self.offset_test(inputs, offset_h_maps, offset_w_maps)\n",
    "                    print('offline')\n",
    "                elif self.configer.get('test', 'mode') == 'ss_test':\n",
    "                    outputs, prototype = self.ss_test(inputs)\n",
    "                    print('ss_test')\n",
    "                ######################################################################################################################333\n",
    "                \n",
    "\n",
    "                if isinstance(outputs, torch.Tensor):\n",
    "                    outputs = outputs.permute(0, 2, 3, 1).cpu().numpy()\n",
    "                    n = outputs.shape[0]\n",
    "                else:\n",
    "                    outputs = [output.permute(0, 2, 3, 1).cpu().numpy().squeeze() for output in outputs]\n",
    "                    n = len(outputs)\n",
    "                    #######################################################################################################################\n",
    "                    # model output\n",
    "                    \n",
    "                #n is mask channel\n",
    "\n",
    "                for k in range(n):\n",
    "                    image_id += 1\n",
    "                    ori_img_size = metas[k]['ori_img_size']\n",
    "                    border_size = metas[k]['border_size']\n",
    "                    logits = cv2.resize(outputs[k][:border_size[1], :border_size[0]],\n",
    "                                        tuple(ori_img_size), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "                    # save the logits map\n",
    "                    if self.configer.get('test', 'save_prob'):\n",
    "                        prob_path = os.path.join(self.save_dir, \"prob/\", '{}.npy'.format(names[k]))\n",
    "                        FileHelper.make_dirs(prob_path, is_file=True)\n",
    "                        np.save(prob_path, softmax(logits, axis=-1))\n",
    "\n",
    "                    label_img = np.asarray(np.argmax(logits, axis=-1), dtype=np.uint8)\n",
    "                    if self.configer.exists('data', 'reduce_zero_label') and self.configer.get('data',\n",
    "                                                                                               'reduce_zero_label'):\n",
    "                        label_img = label_img + 1\n",
    "                        label_img = label_img.astype(np.uint8)\n",
    "                    if self.configer.exists('data', 'label_list'):\n",
    "                        label_img_ = self.__relabel(label_img)\n",
    "                    else:\n",
    "                        label_img_ = label_img\n",
    "                    label_img_ = Image.fromarray(label_img_, 'P')\n",
    "                    if 'subfolder' not in data_dict or len(subfolder[k]) == 0:\n",
    "                        label_path = os.path.join(self.save_dir, \"label/\", '{}.png'.format(names[k]))\n",
    "                    else:\n",
    "                        label_path = os.path.join(self.save_dir, \"label/\", '{}/{}.png'.format(subfolder[k], names[k]))\n",
    "\n",
    "                    FileHelper.make_dirs(label_path, is_file=True)\n",
    "                    ImageHelper.save(label_img_, label_path)\n",
    "\n",
    "                    # colorize the label-map\n",
    "                    if os.environ.get('save_gt_label'):\n",
    "                        if self.configer.exists('data', 'reduce_zero_label') and self.configer.get('data','reduce_zero_label'):\n",
    "                            label_img = labels[k]\n",
    "                            label_img = np.asarray(label_img, dtype=np.uint8)\n",
    "                        color_img_ = Image.fromarray(label_img)\n",
    "                        color_img_.putpalette(colors)\n",
    "                        vis_path = os.path.join(self.save_dir, \"gt_vis/\", '{}.png'.format(names[k]))\n",
    "                        FileHelper.make_dirs(vis_path, is_file=True)\n",
    "                        ImageHelper.save(color_img_, save_path=vis_path)\n",
    "                    else:\n",
    "                        color_img_ = Image.fromarray(label_img)\n",
    "                        color_img_.putpalette(colors)\n",
    "                        vis_path = os.path.join(self.save_dir, \"vis/\", '{}.png'.format(names[k]))\n",
    "                        FileHelper.make_dirs(vis_path, is_file=True)\n",
    "                        ImageHelper.save(color_img_, save_path=vis_path)\n",
    "                        \n",
    "            self.batch_time.update(time.time() - start_time)\n",
    "            start_time = time.time()\n",
    "            \n",
    "            break\n",
    "        \n",
    "#         return prototype\n",
    "        \n",
    "\n",
    "    def ss_test(self, inputs, scale=1):\n",
    "        if isinstance(inputs, torch.Tensor):\n",
    "            n, c, h, w = inputs.size(0), inputs.size(1), inputs.size(2), inputs.size(3)\n",
    "            scaled_inputs = F.interpolate(inputs, size=(int(h * scale), int(w * scale)), mode=\"bilinear\",\n",
    "                                          align_corners=True)\n",
    "            start = timeit.default_timer()\n",
    "            outputs, prototype = self.seg_net.forward(scaled_inputs)\n",
    "            print(\"★★★★★★★★★★★★★★★★★★★★★★★★\")\n",
    "            print(prototype)\n",
    "            print(\"★★★★★★★★★★★★★★★★★★★★★★★★\")\n",
    "            torch.cuda.synchronize()\n",
    "            end = timeit.default_timer()\n",
    "\n",
    "            if isinstance(outputs, list):\n",
    "                outputs = outputs[-1]\n",
    "            elif isinstance(outputs, dict):\n",
    "                outputs = outputs['seg']\n",
    "            elif isinstance(outputs, tuple):\n",
    "                outputs = outputs[-1]\n",
    "            outputs = F.interpolate(outputs, size=(h, w), mode='bilinear', align_corners=True)\n",
    "            \n",
    "            #b c h w\n",
    "            print(\"■■■■■■■■■■■■■■■■■■■■■■■■■\")\n",
    "            print('outputs',outputs.shape)\n",
    "            print('prototype',prototype.shape)\n",
    "            print(\"■■■■■■■■■■■■■■■■■■■■■■■■■\")\n",
    "            return outputs,prototype\n",
    "        \n",
    "        elif isinstance(inputs, collections.Sequence):\n",
    "            device_ids = self.configer.get('gpu')\n",
    "            replicas = nn.parallel.replicate(self.seg_net.module, device_ids)\n",
    "            scaled_inputs, ori_size, outputs = [], [], []\n",
    "            for i, d in zip(inputs, device_ids):\n",
    "                h, w = i.size(1), i.size(2)\n",
    "                ori_size.append((h, w))\n",
    "                i = F.interpolate(i.unsqueeze(0), size=(int(h * scale), int(w * scale)), mode=\"bilinear\",\n",
    "                                  align_corners=True)\n",
    "                scaled_inputs.append(i.cuda(d, non_blocking=True))\n",
    "            scaled_outputs = nn.parallel.parallel_apply(replicas[:len(scaled_inputs)], scaled_inputs)\n",
    "            for i, output in enumerate(scaled_outputs):\n",
    "                outputs.append(F.interpolate(output[-1], size=ori_size[i], mode='bilinear', align_corners=True))\n",
    "            return outputs\n",
    "        else:\n",
    "            raise RuntimeError(\"Unsupport data type: {}\".format(type(inputs)))\n",
    "\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "revolutionary-madagascar",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from itertools import izip\n",
    "except ImportError:\n",
    "    izip = zip\n",
    "\n",
    "# Cityscapes imports\n",
    "try:\n",
    "    from lib.metrics.cityscapes.evaluation.csHelpers import *\n",
    "except:\n",
    "    from cityscapes.evaluation.csHelpers import *\n",
    "    \n",
    "CSUPPORT = True\n",
    "# Check if C-Support is available for better performance\n",
    "if CSUPPORT:\n",
    "    try:\n",
    "        import lib.metrics.cityscapes.evaluation.addToConfusionMatrix as addToConfusionMatrix\n",
    "    except:\n",
    "        CSUPPORT = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "curious-absolute",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CArgs(object):\n",
    "    def __init__(self, data_path=None, out_path=None, predict_path=None):\n",
    "        # Where to look for Cityscapes, note that data path is equal to gt path\n",
    "        if 'CITYSCAPES_DATASET' in os.environ:\n",
    "            self.cityscapesPath = os.environ['CITYSCAPES_DATASET']\n",
    "        else:\n",
    "            self.cityscapesPath = os.path.join(data_path)\n",
    "\n",
    "        if 'CITYSCAPES_EXPORT_DIR' in os.environ:\n",
    "            export_dir = os.environ['CITYSCAPES_EXPORT_DIR']\n",
    "            if not os.path.isdir(export_dir):\n",
    "                raise ValueError(\"CITYSCAPES_EXPORT_DIR {} is not a directory\".format(export_dir))\n",
    "            self.exportFile = \"{}/resultPixelLevelSemanticLabeling.json\".format(export_dir)\n",
    "        else:\n",
    "            self.exportFile = os.path.join(out_path, \"evaluationResults\", \"resultPixelLevelSemanticLabeling.json\")\n",
    "        # Parameters that should be modified by user\n",
    "        self.groundTruthSearch  = os.path.join( self.cityscapesPath, \"*.png\" )\n",
    "\n",
    "        # Remaining params\n",
    "        self.evalInstLevelScore = True\n",
    "        self.evalPixelAccuracy  = True\n",
    "        self.evalLabels         = []\n",
    "        self.printRow           = 5\n",
    "        self.normalized         = True\n",
    "        self.colorized          = hasattr(sys.stderr, \"isatty\") and sys.stderr.isatty() and platform.system()=='Linux'\n",
    "        self.bold               = colors.BOLD if self.colorized else \"\"\n",
    "        self.nocol              = colors.ENDC if self.colorized else \"\"\n",
    "        self.JSONOutput         = True\n",
    "        self.quiet              = False\n",
    "\n",
    "        self.avgClassSize       = {\n",
    "        \"bicycle\"    :  4672.3249222261 ,\n",
    "        \"caravan\"    : 36771.8241758242 ,\n",
    "        \"motorcycle\" :  6298.7200839748 ,\n",
    "        \"rider\"      :  3930.4788056518 ,\n",
    "        \"bus\"        : 35732.1511111111 ,\n",
    "        \"train\"      : 67583.7075812274 ,\n",
    "        \"car\"        : 12794.0202738185 ,\n",
    "        \"person\"     :  3462.4756337644 ,\n",
    "        \"truck\"      : 27855.1264367816 ,\n",
    "        \"trailer\"    : 16926.9763313609 ,\n",
    "    }\n",
    "\n",
    "        # store some parameters for finding predictions in the args variable\n",
    "        # the values are filled when the method getPrediction is first called\n",
    "        self.predictionPath = predict_path\n",
    "        self.predictionWalk = None\n",
    "## method part\n",
    "def getPrediction( args, groundTruthFile ):\n",
    "    # determine the prediction path, if the method is first called\n",
    "    if not args.predictionPath:\n",
    "        rootPath = None\n",
    "        if 'CITYSCAPES_RESULTS' in os.environ:\n",
    "            rootPath = os.environ['CITYSCAPES_RESULTS']\n",
    "        elif 'CITYSCAPES_DATASET' in os.environ:\n",
    "            rootPath = os.path.join( os.environ['CITYSCAPES_DATASET'] , \"results\" )\n",
    "        else:\n",
    "            rootPath = os.path.join(os.path.dirname(os.path.realpath(__file__)),'..','..','results')\n",
    "\n",
    "        if not os.path.isdir(rootPath):\n",
    "            printError(\"Could not find a result root folder. Please read the instructions of this method.\")\n",
    "\n",
    "        args.predictionPath = rootPath\n",
    "\n",
    "    # walk the prediction path, if not happened yet\n",
    "    if not args.predictionWalk:\n",
    "        walk = []\n",
    "        for root, dirnames, filenames in os.walk(args.predictionPath):\n",
    "            walk.append( (root,filenames) )\n",
    "        args.predictionWalk = walk\n",
    "\n",
    "    csFile = getCsFileInfo(groundTruthFile)\n",
    "    filePattern = \"{}_{}_{}*.png\".format( csFile.city , csFile.sequenceNb , csFile.frameNb )\n",
    "\n",
    "    predictionFile = None\n",
    "    for root, filenames in args.predictionWalk:\n",
    "        for filename in fnmatch.filter(filenames, filePattern):\n",
    "            if not predictionFile:\n",
    "                predictionFile = os.path.join(root, filename)\n",
    "            else:\n",
    "                printError(\"Found multiple predictions for ground truth {}\".format(groundTruthFile))\n",
    "\n",
    "    if not predictionFile:\n",
    "        printError(\"Found no prediction for ground truth {}\".format(groundTruthFile))\n",
    "\n",
    "    return predictionFile\n",
    "\n",
    "# Generate empty confusion matrix and create list of relevant labels\n",
    "def generateMatrix(args):\n",
    "    args.evalLabels = []\n",
    "    for label in labels:\n",
    "        if (label.id < 0):\n",
    "            continue\n",
    "        # we append all found labels, regardless of being ignored\n",
    "        args.evalLabels.append(label.id)\n",
    "    maxId = max(args.evalLabels)\n",
    "    # We use longlong type to be sure that there are no overflows\n",
    "    return np.zeros(shape=(maxId + 1, maxId + 1), dtype=np.ulonglong)\n",
    "\n",
    "\n",
    "def generateInstanceStats(args):\n",
    "    instanceStats = {}\n",
    "    instanceStats[\"classes\"] = {}\n",
    "    instanceStats[\"categories\"] = {}\n",
    "    for label in labels:\n",
    "        if label.hasInstances and not label.ignoreInEval:\n",
    "            instanceStats[\"classes\"][label.name] = {}\n",
    "            instanceStats[\"classes\"][label.name][\"tp\"] = 0.0\n",
    "            instanceStats[\"classes\"][label.name][\"tpWeighted\"] = 0.0\n",
    "            instanceStats[\"classes\"][label.name][\"fn\"] = 0.0\n",
    "            instanceStats[\"classes\"][label.name][\"fnWeighted\"] = 0.0\n",
    "    for category in category2labels:\n",
    "        labelIds = []\n",
    "        allInstances = True\n",
    "        for label in category2labels[category]:\n",
    "            if label.id < 0:\n",
    "                continue\n",
    "            if not label.hasInstances:\n",
    "                allInstances = False\n",
    "                break\n",
    "            labelIds.append(label.id)\n",
    "        if not allInstances:\n",
    "            continue\n",
    "\n",
    "        instanceStats[\"categories\"][category] = {}\n",
    "        instanceStats[\"categories\"][category][\"tp\"] = 0.0\n",
    "        instanceStats[\"categories\"][category][\"tpWeighted\"] = 0.0\n",
    "        instanceStats[\"categories\"][category][\"fn\"] = 0.0\n",
    "        instanceStats[\"categories\"][category][\"fnWeighted\"] = 0.0\n",
    "        instanceStats[\"categories\"][category][\"labelIds\"] = labelIds\n",
    "\n",
    "    return instanceStats\n",
    "\n",
    "\n",
    "# Get absolute or normalized value from field in confusion matrix.\n",
    "def getMatrixFieldValue(confMatrix, i, j, args):\n",
    "    if args.normalized:\n",
    "        rowSum = confMatrix[i].sum()\n",
    "        if (rowSum == 0):\n",
    "            return float('nan')\n",
    "        return float(confMatrix[i][j]) / rowSum\n",
    "    else:\n",
    "        return confMatrix[i][j]\n",
    "\n",
    "\n",
    "# Calculate and return IOU score for a particular label\n",
    "def getIouScoreForLabel(label, confMatrix, args):\n",
    "    if id2label[label].ignoreInEval:\n",
    "        return float('nan')\n",
    "\n",
    "    # the number of true positive pixels for this label\n",
    "    # the entry on the diagonal of the confusion matrix\n",
    "    tp = np.longlong(confMatrix[label, label])\n",
    "\n",
    "    # the number of false negative pixels for this label\n",
    "    # the row sum of the matching row in the confusion matrix\n",
    "    # minus the diagonal entry\n",
    "    fn = np.longlong(confMatrix[label, :].sum()) - tp\n",
    "\n",
    "    # the number of false positive pixels for this labels\n",
    "    # Only pixels that are not on a pixel with ground truth label that is ignored\n",
    "    # The column sum of the corresponding column in the confusion matrix\n",
    "    # without the ignored rows and without the actual label of interest\n",
    "    notIgnored = [l for l in args.evalLabels if not id2label[l].ignoreInEval and not l == label]\n",
    "    fp = np.longlong(confMatrix[notIgnored, label].sum())\n",
    "\n",
    "    # the denominator of the IOU score\n",
    "    denom = (tp + fp + fn)\n",
    "    if denom == 0:\n",
    "        return float('nan')\n",
    "\n",
    "    # return IOU\n",
    "    return float(tp) / denom\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Calculate and return IOU score for a particular label\n",
    "def getInstanceIouScoreForLabel(label, confMatrix, instStats, args):\n",
    "    if id2label[label].ignoreInEval:\n",
    "        return float('nan')\n",
    "\n",
    "    labelName = id2label[label].name\n",
    "    if not labelName in instStats[\"classes\"]:\n",
    "        return float('nan')\n",
    "\n",
    "    tp = instStats[\"classes\"][labelName][\"tpWeighted\"]\n",
    "    fn = instStats[\"classes\"][labelName][\"fnWeighted\"]\n",
    "    # false postives computed as above\n",
    "    notIgnored = [l for l in args.evalLabels if not id2label[l].ignoreInEval and not l == label]\n",
    "    fp = np.longlong(confMatrix[notIgnored, label].sum())\n",
    "\n",
    "    # the denominator of the IOU score\n",
    "    denom = (tp + fp + fn)\n",
    "    if denom == 0:\n",
    "        return float('nan')\n",
    "\n",
    "    # return IOU\n",
    "    return float(tp) / denom\n",
    "\n",
    "\n",
    "# Calculate prior for a particular class id.\n",
    "def getPrior(label, confMatrix):\n",
    "    return float(confMatrix[label, :].sum()) / confMatrix.sum()\n",
    "\n",
    "\n",
    "# Get average of scores.\n",
    "# Only computes the average over valid entries.\n",
    "def getScoreAverage(scoreList, args):\n",
    "    validScores = 0\n",
    "    scoreSum = 0.0\n",
    "    for score in scoreList:\n",
    "        if not math.isnan(scoreList[score]):\n",
    "            validScores += 1\n",
    "            scoreSum += scoreList[score]\n",
    "    if validScores == 0:\n",
    "        return float('nan')\n",
    "    return scoreSum / validScores\n",
    "\n",
    "\n",
    "# Calculate and return IOU score for a particular category\n",
    "def getIouScoreForCategory(category, confMatrix, args):\n",
    "    # All labels in this category\n",
    "    labels = category2labels[category]\n",
    "    # The IDs of all valid labels in this category\n",
    "    labelIds = [label.id for label in labels if not label.ignoreInEval and label.id in args.evalLabels]\n",
    "    # If there are no valid labels, then return NaN\n",
    "    if not labelIds:\n",
    "        return float('nan')\n",
    "\n",
    "    # the number of true positive pixels for this category\n",
    "    # this is the sum of all entries in the confusion matrix\n",
    "    # where row and column belong to a label ID of this category\n",
    "    tp = np.longlong(confMatrix[labelIds, :][:, labelIds].sum())\n",
    "\n",
    "    # the number of false negative pixels for this category\n",
    "    # that is the sum of all rows of labels within this category\n",
    "    # minus the number of true positive pixels\n",
    "    fn = np.longlong(confMatrix[labelIds, :].sum()) - tp\n",
    "\n",
    "    # the number of false positive pixels for this category\n",
    "    # we count the column sum of all labels within this category\n",
    "    # while skipping the rows of ignored labels and of labels within this category\n",
    "    notIgnoredAndNotInCategory = [l for l in args.evalLabels if\n",
    "                                  not id2label[l].ignoreInEval and id2label[l].category != category]\n",
    "    fp = np.longlong(confMatrix[notIgnoredAndNotInCategory, :][:, labelIds].sum())\n",
    "\n",
    "    # the denominator of the IOU score\n",
    "    denom = (tp + fp + fn)\n",
    "    if denom == 0:\n",
    "        return float('nan')\n",
    "\n",
    "    # return IOU\n",
    "    return float(tp) / denom\n",
    "\n",
    "\n",
    "# Calculate and return IOU score for a particular category\n",
    "def getInstanceIouScoreForCategory(category, confMatrix, instStats, args):\n",
    "    if not category in instStats[\"categories\"]:\n",
    "        return float('nan')\n",
    "    labelIds = instStats[\"categories\"][category][\"labelIds\"]\n",
    "\n",
    "    tp = instStats[\"categories\"][category][\"tpWeighted\"]\n",
    "    fn = instStats[\"categories\"][category][\"fnWeighted\"]\n",
    "\n",
    "    # the number of false positive pixels for this category\n",
    "    # same as above\n",
    "    notIgnoredAndNotInCategory = [l for l in args.evalLabels if\n",
    "                                  not id2label[l].ignoreInEval and id2label[l].category != category]\n",
    "    fp = np.longlong(confMatrix[notIgnoredAndNotInCategory, :][:, labelIds].sum())\n",
    "\n",
    "    # the denominator of the IOU score\n",
    "    denom = (tp + fp + fn)\n",
    "    if denom == 0:\n",
    "        return float('nan')\n",
    "\n",
    "    # return IOU\n",
    "    return float(tp) / denom\n",
    "\n",
    "\n",
    "# create a dictionary containing all relevant results\n",
    "def createResultDict(confMatrix, classScores, classInstScores, categoryScores, categoryInstScores,\n",
    "                     perImageStats, args):\n",
    "    # write JSON result file\n",
    "    wholeData = {}\n",
    "    wholeData[\"confMatrix\"] = confMatrix.tolist()\n",
    "    wholeData[\"priors\"] = {}\n",
    "    wholeData[\"labels\"] = {}\n",
    "    for label in args.evalLabels:\n",
    "        wholeData[\"priors\"][id2label[label].name] = getPrior(label, confMatrix)\n",
    "        wholeData[\"labels\"][id2label[label].name] = label\n",
    "    wholeData[\"classScores\"] = classScores\n",
    "    wholeData[\"classInstScores\"] = classInstScores\n",
    "    wholeData[\"categoryScores\"] = categoryScores\n",
    "    wholeData[\"categoryInstScores\"] = categoryInstScores\n",
    "    wholeData[\"averageScoreClasses\"] = getScoreAverage(classScores, args)\n",
    "    wholeData[\"averageScoreInstClasses\"] = getScoreAverage(classInstScores, args)\n",
    "    wholeData[\"averageScoreCategories\"] = getScoreAverage(categoryScores, args)\n",
    "    wholeData[\"averageScoreInstCategories\"] = getScoreAverage(categoryInstScores, args)\n",
    "\n",
    "    if perImageStats:\n",
    "        wholeData[\"perImageScores\"] = perImageStats\n",
    "\n",
    "    return wholeData\n",
    "\n",
    "\n",
    "def writeJSONFile(wholeData, args):\n",
    "    path = os.path.dirname(args.exportFile)\n",
    "    ensurePath(path)\n",
    "    writeDict2JSON(wholeData, args.exportFile)\n",
    "\n",
    "\n",
    "# Print confusion matrix\n",
    "def printConfMatrix(confMatrix, args):\n",
    "    # print line\n",
    "    print(\"\\b{text:{fill}>{width}}\".format(width=15, fill='-', text=\" \"), end=' ')\n",
    "    for label in args.evalLabels:\n",
    "        print(\"\\b{text:{fill}>{width}}\".format(width=args.printRow + 2, fill='-', text=\" \"), end=' ')\n",
    "    print(\"\\b{text:{fill}>{width}}\".format(width=args.printRow + 3, fill='-', text=\" \"))\n",
    "\n",
    "    # print label names\n",
    "    print(\"\\b{text:>{width}} |\".format(width=13, text=\"\"), end=' ')\n",
    "    for label in args.evalLabels:\n",
    "        print(\"\\b{text:^{width}} |\".format(width=args.printRow, text=id2label[label].name[0]), end=' ')\n",
    "    print(\"\\b{text:>{width}} |\".format(width=6, text=\"Prior\"))\n",
    "\n",
    "    # print line\n",
    "    print(\"\\b{text:{fill}>{width}}\".format(width=15, fill='-', text=\" \"), end=' ')\n",
    "    for label in args.evalLabels:\n",
    "        print(\"\\b{text:{fill}>{width}}\".format(width=args.printRow + 2, fill='-', text=\" \"), end=' ')\n",
    "    print(\"\\b{text:{fill}>{width}}\".format(width=args.printRow + 3, fill='-', text=\" \"))\n",
    "\n",
    "    # print matrix\n",
    "    for x in range(0, confMatrix.shape[0]):\n",
    "        if (not x in args.evalLabels):\n",
    "            continue\n",
    "        # get prior of this label\n",
    "        prior = getPrior(x, confMatrix)\n",
    "        # skip if label does not exist in ground truth\n",
    "        if prior < 1e-9:\n",
    "            continue\n",
    "\n",
    "        # print name\n",
    "        name = id2label[x].name\n",
    "        if len(name) > 13:\n",
    "            name = name[:13]\n",
    "        print(\"\\b{text:>{width}} |\".format(width=13, text=name), end=' ')\n",
    "        # print matrix content\n",
    "        for y in range(0, len(confMatrix[x])):\n",
    "            if (not y in args.evalLabels):\n",
    "                continue\n",
    "            matrixFieldValue = getMatrixFieldValue(confMatrix, x, y, args)\n",
    "            print(getColorEntry(matrixFieldValue, args) + \"\\b{text:>{width}.2f}  \".format(width=args.printRow,\n",
    "                                                                                          text=matrixFieldValue) + args.nocol,\n",
    "                  end=' ')\n",
    "        # print prior\n",
    "        print(getColorEntry(prior, args) + \"\\b{text:>{width}.4f} \".format(width=6, text=prior) + args.nocol)\n",
    "    # print line\n",
    "    print(\"\\b{text:{fill}>{width}}\".format(width=15, fill='-', text=\" \"), end=' ')\n",
    "    for label in args.evalLabels:\n",
    "        print(\"\\b{text:{fill}>{width}}\".format(width=args.printRow + 2, fill='-', text=\" \"), end=' ')\n",
    "    print(\"\\b{text:{fill}>{width}}\".format(width=args.printRow + 3, fill='-', text=\" \"), end=' ')\n",
    "\n",
    "\n",
    "# Print intersection-over-union scores for all classes.\n",
    "def printClassScores(scoreList, instScoreList, args):\n",
    "    if (args.quiet):\n",
    "        return\n",
    "    print(args.bold + \"classes          IoU      nIoU\" + args.nocol)\n",
    "    print(\"--------------------------------\")\n",
    "    for label in args.evalLabels:\n",
    "        if (id2label[label].ignoreInEval):\n",
    "            continue\n",
    "        labelName = str(id2label[label].name)\n",
    "        iouStr = getColorEntry(scoreList[labelName], args) + \"{val:>5.6f}\".format(\n",
    "            val=scoreList[labelName]) + args.nocol\n",
    "        niouStr = getColorEntry(instScoreList[labelName], args) + \"{val:>5.6f}\".format(\n",
    "            val=instScoreList[labelName]) + args.nocol\n",
    "        print(\"{:<14}: \".format(labelName) + iouStr + \"    \" + niouStr)\n",
    "\n",
    "\n",
    "# Print intersection-over-union scores for all categorys.\n",
    "def printCategoryScores(scoreDict, instScoreDict, args):\n",
    "    if (args.quiet):\n",
    "        return\n",
    "    print(args.bold + \"categories       IoU      nIoU\" + args.nocol)\n",
    "    print(\"--------------------------------\")\n",
    "    for categoryName in scoreDict:\n",
    "        if all(label.ignoreInEval for label in category2labels[categoryName]):\n",
    "            continue\n",
    "        iouStr = getColorEntry(scoreDict[categoryName], args) + \"{val:>5.6f}\".format(\n",
    "            val=scoreDict[categoryName]) + args.nocol\n",
    "        niouStr = getColorEntry(instScoreDict[categoryName], args) + \"{val:>5.6f}\".format(\n",
    "            val=instScoreDict[categoryName]) + args.nocol\n",
    "        print(\"{:<14}: \".format(categoryName) + iouStr + \"    \" + niouStr)\n",
    "\n",
    "####################################################################################################\n",
    "#Inf fun\n",
    "####################################################################################################\n",
    "class EvalPixel():\n",
    "    def __init__(self, args, predictionImgList = None, groundTruthImgList = None):\n",
    "        self.args = args\n",
    "        self.predictionImgList = predictionImgList\n",
    "        self.groundTruthImgList = groundTruthImgList\n",
    "        if predictionImgList is None or groundTruthImgList is None:\n",
    "            self.groundTruthImgList,  self.predictionImgList = self.getDefaultData(self.args)\n",
    "            \n",
    "    # evaluate image in two lists\n",
    "    def evaluateImgLists(self,predictionImgList, groundTruthImgList, args):\n",
    "        if len(predictionImgList) != len(groundTruthImgList):\n",
    "            printError(\"List of images for prediction and groundtruth are not of equal size.\")\n",
    "        confMatrix = generateMatrix(args)\n",
    "        instStats = generateInstanceStats(args)\n",
    "        perImageStats = {}\n",
    "        nbPixels = 0\n",
    "\n",
    "        if not args.quiet:\n",
    "            print(\"Evaluating {} pairs of images...\".format(len(predictionImgList)))\n",
    "\n",
    "        # Evaluate all pairs of images and save them into a matrix\n",
    "        for i in range(len(predictionImgList)):\n",
    "            predictionImgFileName = predictionImgList[i]\n",
    "            groundTruthImgFileName = groundTruthImgList[i]\n",
    "            # print \"Evaluate \", predictionImgFileName, \"<>\", groundTruthImgFileName\n",
    "            ##################################################################################################################################\n",
    "            # infer mask code here\n",
    "            ###################################################################################################################################\n",
    "            nbPixels += self.evaluatePair(predictionImgFileName, groundTruthImgFileName, confMatrix, instStats,\n",
    "                                     perImageStats, args)\n",
    "            print(nbPixels)\n",
    "\n",
    "            # sanity check\n",
    "\n",
    "            if confMatrix.sum() != nbPixels:\n",
    "                pass\n",
    "                # printError(\n",
    "                #     'Number of analyzed pixels and entries in confusion matrix disagree: contMatrix {}, pixels {}'.format(\n",
    "                #         confMatrix.sum(), nbPixels))\n",
    "\n",
    "            if not args.quiet:\n",
    "                print(\"\\rImages Processed: {}\".format(i + 1), end=' ')\n",
    "                sys.stdout.flush()\n",
    "                \n",
    "            #########################################################################################debug True##############\n",
    "            print(\"finish debug\")\n",
    "            break\n",
    "        if not args.quiet:\n",
    "            print(\"\\n\")\n",
    "\n",
    "        # sanity check\n",
    "        if confMatrix.sum() != nbPixels:\n",
    "            pass\n",
    "        #     printError(\n",
    "        #         'Number of analyzed pixels and entries in confusion matrix disagree: contMatrix {}, pixels {}'.format(\n",
    "        #             confMatrix.sum(), nbPixels))\n",
    "\n",
    "        # print confusion matrix\n",
    "        if (not args.quiet):\n",
    "            printConfMatrix(confMatrix, args)\n",
    "\n",
    "        # print accuracy\n",
    "        # Calculate and return IOU score for a particular label\n",
    "        # pdb.set_trace()\n",
    "        \n",
    "        acc = np.diag(confMatrix).sum() / confMatrix.sum()\n",
    "        print(\"pixel accuracy\")\n",
    "        print(acc)\n",
    "\n",
    "        # Calculate IOU scores on class level from matrix\n",
    "        classScoreList = {}\n",
    "        for label in args.evalLabels:\n",
    "            labelName = id2label[label].name\n",
    "            classScoreList[labelName] = getIouScoreForLabel(label, confMatrix, args)\n",
    "\n",
    "        # Calculate instance IOU scores on class level from matrix\n",
    "        classInstScoreList = {}\n",
    "        for label in args.evalLabels:\n",
    "            labelName = id2label[label].name\n",
    "            classInstScoreList[labelName] = getInstanceIouScoreForLabel(label, confMatrix, instStats, args)\n",
    "\n",
    "        # Print IOU scores\n",
    "        if (not args.quiet):\n",
    "            print(\"\")\n",
    "            print(\"\")\n",
    "            printClassScores(classScoreList, classInstScoreList, args)\n",
    "            iouAvgStr = getColorEntry(getScoreAverage(classScoreList, args), args) + \"{avg:5.6f}\".format(\n",
    "                avg=getScoreAverage(classScoreList, args)) + args.nocol\n",
    "            niouAvgStr = getColorEntry(getScoreAverage(classInstScoreList, args), args) + \"{avg:5.6f}\".format(\n",
    "                avg=getScoreAverage(classInstScoreList, args)) + args.nocol\n",
    "            print(\"--------------------------------\")\n",
    "            print(\"Score Average : \" + iouAvgStr + \"    \" + niouAvgStr)\n",
    "            print(\"--------------------------------\")\n",
    "            print(\"\")\n",
    "\n",
    "        # Calculate IOU scores on category level from matrix\n",
    "        categoryScoreList = {}\n",
    "        for category in category2labels.keys():\n",
    "            categoryScoreList[category] = getIouScoreForCategory(category, confMatrix, args)\n",
    "\n",
    "        # Calculate instance IOU scores on category level from matrix\n",
    "        categoryInstScoreList = {}\n",
    "        for category in category2labels.keys():\n",
    "            categoryInstScoreList[category] = getInstanceIouScoreForCategory(category, confMatrix, instStats, args)\n",
    "\n",
    "        # Print IOU scores\n",
    "        if (not args.quiet):\n",
    "            print(\"\")\n",
    "            printCategoryScores(categoryScoreList, categoryInstScoreList, args)\n",
    "            iouAvgStr = getColorEntry(getScoreAverage(categoryScoreList, args), args) + \"{avg:5.6f}\".format(\n",
    "                avg=getScoreAverage(categoryScoreList, args)) + args.nocol\n",
    "            niouAvgStr = getColorEntry(getScoreAverage(categoryInstScoreList, args), args) + \"{avg:5.6f}\".format(\n",
    "                avg=getScoreAverage(categoryInstScoreList, args)) + args.nocol\n",
    "            print(\"--------------------------------\")\n",
    "            print(\"Score Average : \" + iouAvgStr + \"    \" + niouAvgStr)\n",
    "            print(\"--------------------------------\")\n",
    "            print(\"\")\n",
    "\n",
    "        # write result file\n",
    "        allResultsDict = createResultDict(confMatrix, classScoreList, classInstScoreList, categoryScoreList,\n",
    "                                          categoryInstScoreList, perImageStats, args)\n",
    "        # writeJSONFile(allResultsDict, args)\n",
    "\n",
    "        # return confusion matrix\n",
    "        return allResultsDict\n",
    "\n",
    "    # Main evaluation method. Evaluates pairs of prediction and ground truth\n",
    "    # images which are passed as arguments.\n",
    "    def evaluatePair(self,predictionImgFileName, groundTruthImgFileName, confMatrix, instanceStats, perImageStats, args):\n",
    "        # Loading all resources for evaluation.\n",
    "        try:\n",
    "            predictionImg = Image.open(predictionImgFileName)\n",
    "            predictionNp = np.array(predictionImg)\n",
    "        except:\n",
    "            printError(\"Unable to load \" + predictionImgFileName)\n",
    "        try:\n",
    "            groundTruthImg = Image.open(groundTruthImgFileName)\n",
    "            groundTruthNp = np.array(groundTruthImg)\n",
    "        except:\n",
    "            printError(\"Unable to load \" + groundTruthImgFileName)\n",
    "        # load ground truth instances, if needed\n",
    "        if args.evalInstLevelScore:\n",
    "            groundTruthInstanceImgFileName = groundTruthImgFileName.replace(\"labelIds\", \"instanceIds\")\n",
    "            try:\n",
    "                instanceImg = Image.open(groundTruthInstanceImgFileName)\n",
    "                instanceNp = np.array(instanceImg)\n",
    "            except:\n",
    "                printError(\"Unable to load \" + groundTruthInstanceImgFileName)\n",
    "\n",
    "        # Check for equal image sizes\n",
    "        if (predictionImg.size[0] != groundTruthImg.size[0]):\n",
    "            printError(\n",
    "                \"Image widths of \" + predictionImgFileName + \" and \" + groundTruthImgFileName + \" are not equal.\")\n",
    "        if (predictionImg.size[1] != groundTruthImg.size[1]):\n",
    "            printError(\n",
    "                \"Image heights of \" + predictionImgFileName + \" and \" + groundTruthImgFileName + \" are not equal.\")\n",
    "        if (len(predictionNp.shape) != 2):\n",
    "            printError(\"Predicted image has multiple channels.\")\n",
    "\n",
    "        imgWidth = predictionImg.size[0]\n",
    "        imgHeight = predictionImg.size[1]\n",
    "        nbPixels = imgWidth * imgHeight\n",
    "\n",
    "        # Evaluate images\n",
    "        if (CSUPPORT):\n",
    "            # using cython\n",
    "            confMatrix = addToConfusionMatrix.cEvaluatePair(predictionNp, groundTruthNp, confMatrix, args.evalLabels)\n",
    "\n",
    "        else:\n",
    "            # the slower python way\n",
    "            for (groundTruthImgPixel, predictionImgPixel) in izip(groundTruthImg.getdata(), predictionImg.getdata()):\n",
    "                if (not groundTruthImgPixel in args.evalLabels):\n",
    "                    printError(\"Unknown label with id {:}\".format(groundTruthImgPixel))\n",
    "\n",
    "                confMatrix[groundTruthImgPixel][predictionImgPixel] += 1\n",
    "\n",
    "        if args.evalInstLevelScore:\n",
    "            # Generate category masks\n",
    "            categoryMasks = {}\n",
    "            for category in instanceStats[\"categories\"]:\n",
    "                categoryMasks[category] = np.in1d(predictionNp,\n",
    "                                                  instanceStats[\"categories\"][category][\"labelIds\"]).reshape(\n",
    "                    predictionNp.shape)\n",
    "\n",
    "            instList = np.unique(instanceNp[instanceNp > 1000])\n",
    "            for instId in instList:\n",
    "                labelId = int(instId / 1000)\n",
    "                label = id2label[labelId]\n",
    "                if label.ignoreInEval:\n",
    "                    continue\n",
    "\n",
    "                mask = instanceNp == instId\n",
    "                instSize = np.count_nonzero(mask)\n",
    "\n",
    "                tp = np.count_nonzero(predictionNp[mask] == labelId)\n",
    "                fn = instSize - tp\n",
    "\n",
    "                weight = args.avgClassSize[label.name] / float(instSize)\n",
    "                tpWeighted = float(tp) * weight\n",
    "                fnWeighted = float(fn) * weight\n",
    "\n",
    "                instanceStats[\"classes\"][label.name][\"tp\"] += tp\n",
    "                instanceStats[\"classes\"][label.name][\"fn\"] += fn\n",
    "                instanceStats[\"classes\"][label.name][\"tpWeighted\"] += tpWeighted\n",
    "                instanceStats[\"classes\"][label.name][\"fnWeighted\"] += fnWeighted\n",
    "\n",
    "                category = label.category\n",
    "                if category in instanceStats[\"categories\"]:\n",
    "                    catTp = 0\n",
    "                    catTp = np.count_nonzero(np.logical_and(mask, categoryMasks[category]))\n",
    "                    catFn = instSize - catTp\n",
    "\n",
    "                    catTpWeighted = float(catTp) * weight\n",
    "                    catFnWeighted = float(catFn) * weight\n",
    "\n",
    "                    instanceStats[\"categories\"][category][\"tp\"] += catTp\n",
    "                    instanceStats[\"categories\"][category][\"fn\"] += catFn\n",
    "                    instanceStats[\"categories\"][category][\"tpWeighted\"] += catTpWeighted\n",
    "                    instanceStats[\"categories\"][category][\"fnWeighted\"] += catFnWeighted\n",
    "\n",
    "        if True: # evaluate pixel accuracy\n",
    "            notIgnoredLabels = [l for l in args.evalLabels if not id2label[l].ignoreInEval]\n",
    "            notIgnoredPixels = np.in1d(groundTruthNp, notIgnoredLabels, invert=True).reshape(groundTruthNp.shape)\n",
    "            erroneousPixels = np.logical_and(notIgnoredPixels, (predictionNp != groundTruthNp))\n",
    "            perImageStats[predictionImgFileName] = {}\n",
    "            perImageStats[predictionImgFileName][\"nbNotIgnoredPixels\"] = np.count_nonzero(notIgnoredPixels)\n",
    "            perImageStats[predictionImgFileName][\"nbCorrectPixels\"] = np.count_nonzero(erroneousPixels)\n",
    "            # print(\"all pixel_count:\"+str(perImageStats[predictionImgFileName][\"nbNotIgnoredPixels\"]))\n",
    "            # print(\"correct pixel_count:\"+str(perImageStats[predictionImgFileName][\"nbCorrectPixels\"]))\n",
    "            # print(\"pixel_accuracy:\"+str((float(perImageStats[predictionImgFileName][\"nbCorrectPixels\"])/perImageStats[predictionImgFileName][\"nbNotIgnoredPixels\"])))\n",
    "\n",
    "        return nbPixels\n",
    "\n",
    "\n",
    "    # launch the process\n",
    "    def run(self):\n",
    "        self.evaluateImgLists(self.predictionImgList, self.groundTruthImgList, self.args)\n",
    "\n",
    "    # get the default data\n",
    "    def getDefaultData(self, args):\n",
    "        groundTruthImgList, predictionImgList = [], []\n",
    "        groundTruthImgList = glob.glob(args.groundTruthSearch)\n",
    "        if not groundTruthImgList:\n",
    "            printError(\"Cannot find any ground truth images to use for evaluation. Searched for: {}\".format(\n",
    "                args.groundTruthSearch))\n",
    "        # get the corresponding prediction for each ground truth imag\n",
    "        for gt in groundTruthImgList:\n",
    "            predictionImgList.append(getPrediction(args, gt))\n",
    "        return groundTruthImgList, predictionImgList\n",
    "\n",
    "\n",
    "class CityscapesEvaluator(object):\n",
    "\n",
    "    def evaluate(self, pred_dir=None, gt_dir=None):\n",
    "        \"\"\"\n",
    "        :param pred_dir: directory of model output results(must be consistent with val directory)\n",
    "        :param gt_dir: directory of  cityscapes data(root)\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        pred_path = pred_dir\n",
    "        data_path = gt_dir\n",
    "        print(\"evaluate the result...\")\n",
    "        args = CArgs(data_path=data_path, out_path=data_path, predict_path=pred_path)\n",
    "        ob = EvalPixel(args)\n",
    "        ob.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "mounted-stationery",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-05 15:43:43,451 INFO    [module_runner.py, 46] BN Type is torchsyncbn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Model Now ...\n",
      "hrnet_w48_proto\n",
      "ok\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-05 15:43:44,793 INFO    [module_runner.py, 87] Loading checkpoint from /tmp/working/workspace/ProtoSeg_local/output/Cityscapes/checkpoints/cityscapes/hrnet_w48_proto_lr1x_hrnet_proto_80k_latest.pth...\n",
      "2022-11-05 15:43:44,945 INFO    [module_runner.py, 117] {'dataset': 'cityscapes', 'method': 'fcn_segmentor', 'data': {'image_tool': 'cv2', 'input_mode': 'BGR', 'num_classes': 19, 'label_list': [7, 8, 11, 12, 13, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 31, 32, 33], 'data_dir': ['/tmp/working/workspace/ProtoSeg_local/data/Cityscapes'], 'workers': 8, 'include_val': False, 'include_coarse': False, 'only_coarse': False, 'only_mapillary': False, 'only_small': False, 'include_atr': False, 'include_cihp': False, 'drop_last': True}, 'train': {'batch_size': 8, 'data_transformer': {'size_mode': 'fix_size', 'input_size': [1024, 512], 'align_method': 'only_pad', 'pad_mode': 'random'}}, 'val': {'batch_size': 4, 'mode': 'ss_test', 'data_transformer': {'size_mode': 'fix_size', 'input_size': [2048, 1024], 'align_method': 'only_pad'}}, 'test': {'batch_size': 4, 'mode': 'ss_test', 'out_dir': 'none', 'data_transformer': {'size_mode': 'fix_size', 'input_size': [2048, 1024], 'align_method': 'only_pad'}, 'test_img': None, 'test_dir': None, 'save_prob': False}, 'train_trans': {'trans_seq': ['random_resize', 'random_crop', 'random_hflip', 'random_brightness'], 'random_brightness': {'ratio': 1.0, 'shift_value': 10}, 'random_hflip': {'ratio': 0.5, 'swap_pair': []}, 'random_resize': {'ratio': 1.0, 'method': 'random', 'scale_range': [0.5, 2.0], 'aspect_range': [0.9, 1.1]}, 'random_crop': {'ratio': 1.0, 'crop_size': [1024, 512], 'method': 'random', 'allow_outside_center': False}}, 'val_trans': {'trans_seq': []}, 'normalize': {'div_value': 255.0, 'mean_value': [0.485, 0.456, 0.406], 'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225]}, 'checkpoints': {'checkpoints_name': 'hrnet_w48_proto_lr1x_hrnet_proto_80k', 'checkpoints_dir': './checkpoints/cityscapes', 'save_iters': 1000, 'checkpoints_root': '/cluster/scratch/tiazhou/Openseg/Cityscapes', 'save_epoch': None}, 'network': {'backbone': 'hrnet48', 'multi_grid': [1, 1, 1], 'model_name': 'hrnet_w48_proto', 'bn_type': 'torchsyncbn', 'stride': 8, 'factors': [[8, 8]], 'loss_weights': {'corr_loss': 0.01, 'aux_loss': 0.4, 'seg_loss': 1.0}, 'pretrained': '/scratch/214330916.tmpdir/hrnetv2_w48_imagenet_pretrained.pth', 'resume': None, 'resume_strict': True, 'resume_continue': False, 'resume_train': True, 'resume_val': True, 'gathered': False, 'loss_balance': True}, 'logging': {'logfile_level': None, 'stdout_level': 'info', 'log_file': './log/cityscapes/fs_baseocnet_cityscapes_seg.log', 'log_format': '%(asctime)s %(levelname)-7s %(message)s', 'rewrite': True, 'log_to_file': False}, 'lr': {'base_lr': 0.01, 'metric': 'iters', 'lr_policy': 'lambda_poly', 'step': {'gamma': 0.5, 'step_size': 100}, 'nbb_mult': 1.0, 'is_warm': False}, 'solver': {'display_iter': 10, 'test_interval': 2000, 'max_iters': 80000, 'max_epoch': None}, 'optim': {'optim_method': 'sgd', 'adam': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0.0001}, 'sgd': {'weight_decay': 0.0005, 'momentum': 0.9, 'nesterov': False}, 'group_method': None}, 'loss': {'loss_type': 'pixel_prototype_ce_loss', 'params': {'ce_weight': [0.8373, 0.918, 0.866, 1.0345, 1.0166, 0.9969, 0.9754, 1.0489, 0.8786, 1.0023, 0.9539, 0.9843, 1.1116, 0.9037, 1.0865, 1.0955, 1.0865, 1.1529, 1.0507], 'ce_reduction': 'elementwise_mean', 'ce_ignore_index': -1, 'ohem_minkeep': 100000, 'ohem_thresh': 0.9}}, 'protoseg': {'gamma': 0.999, 'loss_ppc_weight': 0.01, 'loss_ppd_weight': 0.001, 'num_prototype': 10, 'pretrain_prototype': False, 'use_rmi': False, 'use_prototype': True, 'update_prototype': True, 'warmup_iters': 0}, 'configs': 'configs/cityscapes/H_48_D_4_proto.json', 'phase': 'train', 'gpu': [0, 1, 2, 3], 'seed': 304, 'cudnn': True, 'local_rank': 0, 'distributed': True, 'use_ground_truth': False, 'REMAIN': [], 'project_dir': '/cluster/home/tiazhou/workspace/ProtoSeg_openseg', 'iters': 80000, 'last_iters': 0, 'epoch': 216, 'last_epoch': 0, 'max_performance': 0.7979137582800697, 'performance': 0.8012374527375284, 'min_val_loss': 9999.0, 'val_loss': 9999.0}\n",
      "2022-11-05 15:43:44,955 INFO    [<ipython-input-8-5ac1aa244051>, 95] use DefaultLoader for val ...\n",
      "2022-11-05 15:43:44,960 INFO    [default_loader.py, 38] val 500\n",
      "2022-11-05 15:43:45,919 ERROR   Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "2022-11-05 15:43:45,923 INFO    \n",
      "Unfortunately, your original traceback can not be constructed.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3427, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-16-3efdd166a418>\", line 41, in <module>\n",
      "    model.test()\n",
      "  File \"<ipython-input-13-bb083826d099>\", line 76, in test\n",
      "    for j, data_dict in enumerate(self.test_loader):\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 517, in __next__\n",
      "    data = self._next_data()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1199, in _next_data\n",
      "    return self._process_data(data)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1225, in _process_data\n",
      "    data.reraise()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/_utils.py\", line 429, in reraise\n",
      "    raise self.exc_type(msg)\n",
      "RuntimeError: Caught RuntimeError in DataLoader worker process 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py\", line 202, in _worker_loop\n",
      "    data = fetcher.fetch(index)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 47, in fetch\n",
      "    return self.collate_fn(data)\n",
      "  File \"<ipython-input-8-5ac1aa244051>\", line 107, in <lambda>\n",
      "    collate_fn=lambda *args: collate(\n",
      "  File \"/tmp/working/workspace/PP_seg/lib/datasets/tools/collate.py\", line 175, in collate\n",
      "    return dict({key: stack(batch, data_key=key) for key in data_keys})\n",
      "  File \"/tmp/working/workspace/PP_seg/lib/datasets/tools/collate.py\", line 175, in <dictcomp>\n",
      "    return dict({key: stack(batch, data_key=key) for key in data_keys})\n",
      "  File \"/tmp/working/workspace/PP_seg/lib/datasets/tools/collate.py\", line 25, in stack\n",
      "    return default_collate(samples)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\", line 53, in default_collate\n",
      "    storage = elem.storage()._new_shared(numel)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/storage.py\", line 157, in _new_shared\n",
      "    return cls._new_using_fd(size)\n",
      "RuntimeError: unable to write to file </torch_867_777559746>\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2054, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'RuntimeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/opt/conda/lib/python3.8/inspect.py\", line 1503, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/opt/conda/lib/python3.8/inspect.py\", line 1461, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/opt/conda/lib/python3.8/inspect.py\", line 708, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/opt/conda/lib/python3.8/inspect.py\", line 754, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/opt/conda/lib/python3.8/posixpath.py\", line 391, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/opt/conda/lib/python3.8/posixpath.py\", line 425, in _joinrealpath\n",
      "    if not islink(newpath):\n",
      "  File \"/opt/conda/lib/python3.8/posixpath.py\", line 167, in islink\n",
      "    st = os.lstat(path)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/_utils/signal_handling.py\", line 66, in handler\n",
      "    _error_if_any_worker_fails()\n",
      "RuntimeError: DataLoader worker (pid 907) is killed by signal: Bus error. It is possible that dataloader's workers are out of shared memory. Please try to raise your shared memory limit.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-3efdd166a418>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mTester\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfiger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Load Model Finish'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-bb083826d099>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(self, data_loader)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_dict\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'img'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1198\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1199\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1224\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1225\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1226\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    428\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py\", line 202, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 47, in fetch\n    return self.collate_fn(data)\n  File \"<ipython-input-8-5ac1aa244051>\", line 107, in <lambda>\n    collate_fn=lambda *args: collate(\n  File \"/tmp/working/workspace/PP_seg/lib/datasets/tools/collate.py\", line 175, in collate\n    return dict({key: stack(batch, data_key=key) for key in data_keys})\n  File \"/tmp/working/workspace/PP_seg/lib/datasets/tools/collate.py\", line 175, in <dictcomp>\n    return dict({key: stack(batch, data_key=key) for key in data_keys})\n  File \"/tmp/working/workspace/PP_seg/lib/datasets/tools/collate.py\", line 25, in stack\n    return default_collate(samples)\n  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\", line 53, in default_collate\n    storage = elem.storage()._new_shared(numel)\n  File \"/opt/conda/lib/python3.8/site-packages/torch/storage.py\", line 157, in _new_shared\n    return cls._new_using_fd(size)\nRuntimeError: unable to write to file </torch_867_777559746>\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2053\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2054\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2055\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'RuntimeError' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2054\u001b[0m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2055\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2056\u001b[0;31m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0m\u001b[1;32m   2057\u001b[0m                                             value, tb, tb_offset=tb_offset)\n\u001b[1;32m   2058\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1267\u001b[0;31m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m             )\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[1;32m   1125\u001b[0m                                                                tb_offset)\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "from lib.utils.helpers.file_helper import FileHelper\n",
    "from lib.utils.helpers.image_helper import ImageHelper\n",
    "from lib.utils.tools.logger import Logger as Log\n",
    "from lib.metrics.running_score import RunningScore\n",
    "from lib.vis.seg_visualizer import SegVisualizer\n",
    "from lib.vis.palette import get_cityscapes_colors\n",
    "from segmentor.tools.module_runner import ModuleRunner\n",
    "from segmentor.tools.optim_scheduler import OptimScheduler\n",
    "from pathlib import Path\n",
    "import torch.nn.functional as F\n",
    "import timeit\n",
    "import pdb\n",
    "import cv2\n",
    "\n",
    "import fnmatch\n",
    "import platform\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    INFERENCE = True\n",
    "    parser = argparse.ArgumentParser()\n",
    "    if CFG.model_method == 'fcn':\n",
    "        if CFG.phase == 'infer':\n",
    "            print('Load Model Now ...')\n",
    "            configer = Configer(args_parser = main())\n",
    "            data_dir = configer.get('data', 'data_dir')\n",
    "            \n",
    "            if isinstance(data_dir, str):\n",
    "                data_dir = [data_dir]\n",
    "            abs_data_dir = [os.path.expanduser(x) for x in data_dir]\n",
    "            configer.update(['data', 'data_dir'], abs_data_dir)\n",
    "            \n",
    "            #python\n",
    "            #project_dir = os.path.dirname(os.path.realpath(__file__))\n",
    "            #jupyter\n",
    "            project_dir = os.path.dirname(Path().resolve())\n",
    "            configer.add(['project_dir'], project_dir)\n",
    "            model = None\n",
    "            \n",
    "            model =Tester(configer)\n",
    "            model.test()\n",
    "            print('Load Model Finish')\n",
    "            \n",
    "            if INFERENCE:\n",
    "                print('Inference Starting ...')\n",
    "                args = inference_fn()\n",
    "                cityscapes_evaluator = CityscapesEvaluator()\n",
    "                cityscapes_evaluator.evaluate(pred_dir=args.pred_dir, gt_dir=args.gt_dir)\n",
    "                \n",
    "                print(prototype)\n",
    "  \n",
    "        else:\n",
    "            print('train module will be available')\n",
    "    else:\n",
    "        print('attention models will be available')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organic-celtic",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "graduate-stockholm",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "psychological-newfoundland",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quick-delhi",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "drawn-consciousness",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "taken-shuttle",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "streaming-basket",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
